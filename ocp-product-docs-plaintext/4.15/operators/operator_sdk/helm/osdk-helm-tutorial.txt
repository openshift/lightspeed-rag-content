Operator SDK tutorial for Helm-based Operators

Operator developers can take advantage of Helm support in the Operator SDK to build an example Helm-based Operator for Nginx and manage its lifecycle. This tutorial walks through the following process:

Create a Nginx deployment

Ensure that the deployment size is the same as specified by the Nginx custom resource (CR) spec

Update the Nginx CR status using the status writer with the names of the nginx pods


This process is accomplished using two centerpieces of the Operator Framework:


Operator SDK
The operator-sdk CLI tool and controller-runtime library API
Operator Lifecycle Manager (OLM)
Installation, upgrade, and role-based access control (RBAC) of Operators on a cluster


This tutorial goes into greater detail than Getting started with Operator SDK for Helm-based Operators.
Prerequisites
Operator SDK CLI installed

OpenShift CLI (oc) 4.15+ installed

Logged into an Red Hat OpenShift Container Platform 4.15 cluster with oc with an account that has cluster-admin permissions

To allow the cluster to pull the image, the repository where you push your image must be set as public, or you must configure an image pull secret


Installing the Operator SDK CLI

Getting started with the OpenShift CLI
Creating a project
Use the Operator SDK CLI to create a project called nginx-operator.

Create a directory for the project:

Change to the directory:

Run the operator-sdk init command
with the helm plugin
to initialize the project:

For Helm-based projects, the init command generates the RBAC rules in the config/rbac/role.yaml file based on the resources that would be deployed by the default manifest for the chart. Verify that the rules generated in this file meet the permission requirements of the Operator.


Existing Helm charts
Instead of creating your project with a boilerplate Helm chart, you can alternatively use an existing chart, either from your local file system or a remote chart repository, by using the following flags:

--helm-chart

--helm-chart-repo

--helm-chart-version


If the --helm-chart flag is specified, the --group, --version, and --kind flags become optional. If left unset, the following default values are used:


If the --helm-chart flag specifies a local chart archive, for example example-chart-1.2.0.tgz, or directory, the chart is validated and unpacked or copied into the project. Otherwise, the Operator SDK attempts to fetch the chart from a remote repository.

If a custom repository URL is not specified by the --helm-chart-repo flag, the following chart reference formats are supported:


If a custom repository URL is specified by --helm-chart-repo, the following chart reference format is supported:


If the --helm-chart-version flag is unset, the Operator SDK fetches the latest available version of the Helm chart. Otherwise, it fetches the specified version. The optional --helm-chart-version flag is not used when the chart specified with the --helm-chart flag refers to a specific version, for example when it is a local path or a URL.

For more details and examples, run:

$ operator-sdk init --plugins helm --help
PROJECT file
Among the files generated by the operator-sdk init command is a Kubebuilder PROJECT file. Subsequent operator-sdk commands, as well as help output, that are run from the project root read this file and are aware that the project type is Helm. For example:

domain: example.com
layout:
- helm.sdk.operatorframework.io/v1
plugins:
  manifests.sdk.operatorframework.io/v2: {}
  scorecard.sdk.operatorframework.io/v2: {}
  sdk.x-openshift.io/v1: {}
projectName: nginx-operator
resources:
- api:
    crdVersion: v1
    namespaced: true
  domain: example.com
  group: demo
  kind: Nginx
  version: v1
version: "3"
Understanding the Operator logic
For this example, the nginx-operator project executes the following reconciliation logic for each Nginx custom resource (CR):

Create an Nginx deployment if it does not exist.

Create an Nginx service if it does not exist.

Create an Nginx ingress if it is enabled and does not exist.

Ensure that the deployment, service, and optional ingress match the desired configuration as specified by the Nginx CR, for example the replica count, image, and service type.


By default, the nginx-operator project watches Nginx resource events as shown in the watches.yaml file and executes Helm releases using the specified chart:

# Use the 'create api' subcommand to add watches to this file.
- group: demo
  version: v1
  kind: Nginx
  chart: helm-charts/nginx
# +kubebuilder:scaffold:watch
Sample Helm chart
When a Helm Operator project is created, the Operator SDK creates a sample Helm chart that contains a set of templates for a simple Nginx release.

For this example, templates are available for deployment, service, and ingress resources, along with a NOTES.txt template, which Helm chart developers use to convey helpful information about a release.

If you are not already familiar with Helm charts, review the Helm developer documentation.
Modifying the custom resource spec
Helm uses a concept called values to provide customizations to the defaults of a Helm chart, which are defined in the values.yaml file.

You can override these defaults by setting the desired values in the custom resource (CR) spec. You can use the number of replicas as an example.

The helm-charts/nginx/values.yaml file has a value called replicaCount set to 1 by default. To have two Nginx instances in your deployment, your CR spec must contain replicaCount: 2.

Similarly, the default service port is set to 80. To use 8080, edit the config/samples/demo_v1_nginx.yaml file to set spec.port: 8080,which adds the service port override:


The Helm Operator applies the entire spec as if it was the contents of a values file, just like the helm install -f ./overrides.yaml command.
Enabling proxy support
Operator authors can develop Operators that support network proxies. Cluster administrators configure proxy support for the environment variables that are handled by Operator Lifecycle Manager (OLM). To support proxied clusters, your Operator must inspect the environment for the following standard proxy variables and pass the values to Operands:

HTTP_PROXY

HTTPS_PROXY

NO_PROXY


This tutorial uses HTTP_PROXY as an example environment variable.
A cluster with cluster-wide egress proxy enabled.


Edit the watches.yaml file to include overrides based on an environment variable by adding the overrideValues field:

Add the proxy.http value in the helm-charts/nginx/values.yaml file:

To make sure the chart template supports using the variables, edit the chart template in the helm-charts/nginx/templates/deployment.yaml file to contain the following:

Set the environment variable on the Operator deployment by adding the following to the config/manager/manager.yaml file:
Running the Operator
There are three ways you can use the Operator SDK CLI to build and run your Operator:

Run locally outside the cluster as a Go program.

Run as a deployment on the cluster.

Bundle your Operator and use Operator Lifecycle Manager (OLM) to deploy on the cluster.


Running locally outside the cluster
You can run your Operator project as a Go program outside of the cluster. This is useful for development purposes to speed up deployment and testing.

Run the following command to install the custom resource definitions (CRDs) in the cluster configured in your ~/.kube/config file and run the Operator locally:
Running as a deployment on the cluster
You can run your Operator project as a deployment on your cluster.

Run the following make commands to build and push the Operator image. Modify the IMG argument in the following steps to reference a repository that you have access to. You can obtain an account for storing containers at repository sites such as Quay.io.

Run the following command to deploy the Operator:

Run the following command to verify that the Operator is running:
Bundling an Operator and deploying with Operator Lifecycle Manager
Bundling an Operator
The Operator bundle format is the default packaging method for Operator SDK and Operator Lifecycle Manager (OLM). You can get your Operator ready for use on OLM by using the Operator SDK to build and push your Operator project as a bundle image.

Operator SDK CLI installed on a development workstation

OpenShift CLI (oc) v4.15+ installed

Operator project initialized by using the Operator SDK


Run the following make commands in your Operator project directory to build and push your Operator image. Modify the IMG argument in the following steps to reference a repository that you have access to. You can obtain an account for storing containers at repository sites such as Quay.io.

Create your Operator bundle manifest by running the make bundle command, which invokes several commands, including the Operator SDK generate bundle and bundle validate subcommands:

Build and push your bundle image by running the following commands. OLM consumes Operator bundles using an index image, which reference one or more bundle images.
Deploying an Operator with Operator Lifecycle Manager
Operator Lifecycle Manager (OLM) helps you to install, update, and manage the lifecycle of Operators and their associated services on a Kubernetes cluster. OLM is installed by default on Red Hat OpenShift Container Platform and runs as a Kubernetes extension so that you can use the web console and the OpenShift CLI (oc) for all Operator lifecycle management functions without any additional tools.

The Operator bundle format is the default packaging method for Operator SDK and OLM. You can use the Operator SDK to quickly run a bundle image on OLM to ensure that it runs properly.

Operator SDK CLI installed on a development workstation

Operator bundle image built and pushed to a registry

OLM installed on a Kubernetes-based cluster (v1.16.0 or later if you use apiextensions.k8s.io/v1 CRDs, for example Red Hat OpenShift Container Platform 4.15)

Logged in to the cluster with oc using an account with cluster-admin permissions


Enter the following command to run the Operator on the cluster:
Creating a custom resource
After your Operator is installed, you can test it by creating a custom resource (CR) that is now provided on the cluster by the Operator.

Example Nginx Operator, which provides the Nginx CR, installed on a cluster


Change to the namespace where your Operator is installed. For example, if you deployed the Operator using the make deploy command:

Edit the sample Nginx CR manifest at config/samples/demo_v1_nginx.yaml to contain the following specification:

The Nginx service account requires privileged access to run in Red Hat OpenShift Container Platform. Add the following security context constraint (SCC) to the service account for the nginx-sample pod:

Create the CR:

Ensure that the Nginx Operator creates the deployment for the sample CR with the correct size:

Check the pods and CR status to confirm the status is updated with the Nginx pod names.

Update the deployment size.

Delete the CR by running the following command:

Clean up the resources that have been created as part of this tutorial.
Additional resources
See Project layout for Helm-based Operators to learn about the directory structures created by the Operator SDK.

If a cluster-wide egress proxy is configured, cluster administrators can override the proxy settings or inject a custom CA certificate for specific Operators running on Operator Lifecycle Manager (OLM).