Optimizing storage

Optimizing storage helps to minimize storage use across all resources. By optimizing storage, administrators help ensure that existing storage resources are working in an efficient manner.
Available persistent storage options
Understand your persistent storage options so that you can optimize your Red Hat OpenShift Container Platform environment.


NetApp NFS supports dynamic PV provisioning when using the Trident plugin.
Recommended configurable storage technology
The following table summarizes the recommended and configurable storage technologies for the given Red Hat OpenShift Container Platform cluster application.


A scaled registry is an OpenShift image registry where two or more pod replicas are running.
Specific application storage recommendations
Testing shows issues with using the NFS server on Red Hat Enterprise Linux (RHEL) as storage backend for core services. This includes the OpenShift Container Registry and Quay, Prometheus for monitoring storage, and Elasticsearch for logging storage. Therefore, using RHEL NFS to back PVs used by core services is not recommended.

Other NFS implementations on the marketplace might not have these issues. Contact the individual NFS implementation vendor for more information on any testing that was possibly completed against these Red Hat OpenShift Container Platform core components.
Registry
In a non-scaled/high-availability (HA) OpenShift image registry cluster deployment:

The storage technology does not have to support RWX access mode.

The storage technology must ensure read-after-write consistency.

The preferred storage technology is object storage followed by block storage.

File storage is not recommended for OpenShift image registry cluster deployment with production workloads.
Scaled registry
In a scaled/HA OpenShift image registry cluster deployment:

The storage technology must support RWX access mode.

The storage technology must ensure read-after-write consistency.

The preferred storage technology is object storage.

Red Hat OpenShift Data Foundation (ODF), Amazon Simple Storage Service (Amazon S3), Google Cloud Storage (GCS), Microsoft Azure Blob Storage, and OpenStack Swift are supported.

Object storage should be S3 or Swift compliant.

For non-cloud platforms, such as vSphere and bare metal installations, the only configurable technology is file storage.

Block storage is not configurable.
Metrics
In an Red Hat OpenShift Container Platform hosted metrics cluster deployment:

The preferred storage technology is block storage.

Object storage is not configurable.


It is not recommended to use file storage for a hosted metrics cluster deployment with production workloads.
Logging
In an Red Hat OpenShift Container Platform hosted logging cluster deployment:

Loki Operator:

Elasticsearch Operator:


As of logging version 5.4.3 the Elasticsearch Operator is deprecated and is planned to be removed in a future release. Red Hat will provide bug fixes and support for this feature during the current release lifecycle, but this feature will no longer receive enhancements and will be removed. As an alternative to using the Elasticsearch Operator to manage the default log storage, you can use the Loki Operator.
Applications
Application use cases vary from application to application, as described in the following examples:

Storage technologies that support dynamic PV provisioning have low mount time latencies, and are not tied to nodes to support a healthy cluster.

Application developers are responsible for knowing and understanding the storage requirements for their application, and how it works with the provided storage to ensure that issues do not occur when an application scales or interacts with the storage layer.
Other specific application storage recommendations
It is not recommended to use RAID configurations on Write intensive workloads, such as etcd. If you are running etcd with a RAID configuration, you might be at risk of encountering performance issues with your workloads.
OpenStack Cinder: OpenStack Cinder tends to be adept in ROX access mode use cases.

Databases: Databases (RDBMSs, NoSQL DBs, etc.) tend to perform best with dedicated block storage.

The etcd database must have enough storage and adequate performance capacity to enable a large cluster. Information about monitoring and benchmarking tools to establish ample storage and a high-performance environment is described in Recommended etcd practices.
Data storage management
The following table summarizes the main directories that Red Hat OpenShift Container Platform components write data to.
Optimizing storage performance for Microsoft Azure
Red Hat OpenShift Container Platform and Kubernetes are sensitive to disk performance, and faster storage is recommended, particularly for etcd on the control plane nodes.

For production Azure clusters and clusters with intensive workloads, the virtual machine operating system disk for control plane machines should be able to sustain a tested and recommended minimum throughput of 5000 IOPS / 200MBps. This throughput can be provided by having a minimum of 1 TiB Premium SSD (P30). In Azure and Azure Stack Hub, disk performance is directly dependent on SSD disk sizes. To achieve the throughput supported by a Standard_D8s_v3 virtual machine, or other similar machine types, and the target of 5000 IOPS, at least a P30 disk is required.

Host caching must be set to ReadOnly for low latency and high IOPS and throughput when reading data. Reading data from the cache, which is present either in the VM memory or in the local SSD disk, is much faster than reading from the disk, which is in the blob storage.
Additional resources
Configuring the Elasticsearch log store