Installing the Network Observability Operator

Installing Loki is a recommended prerequisite for using the Network Observability Operator. You can choose to use Network Observability without Loki, but there are some considerations for doing this, described in the previously linked section.

The Loki Operator integrates a gateway that implements multi-tenancy and authentication with Loki for data flow storage. The LokiStack resource manages Loki, which is a scalable, highly-available, multi-tenant log aggregation system, and a web proxy with Red Hat OpenShift Container Platform authentication. The LokiStack proxy uses Red Hat OpenShift Container Platform authentication to enforce multi-tenancy and facilitate the saving and indexing of data in Loki log stores.

The Loki Operator can also be used for configuring the LokiStack log store. The Network Observability Operator requires a dedicated LokiStack separate from the logging.
Network Observability without Loki
You can use Network Observability without Loki by not performing the Loki installation steps and skipping directly to "Installing the Network Observability Operator". If you only want to export flows to a Kafka consumer or IPFIX collector, or you only need dashboard metrics, then you do not need to install Loki or provide storage for Loki.  Without Loki, there won't be a Network Traffic panel under Observe, which means there is no overview charts, flow table, or topology. The following table compares available features with and without Loki:


Export enriched network flow data.
Installing the Loki Operator
The Loki Operator versions 5.7+ are the supported Loki Operator versions for Network Observability; these versions provide the ability to create a LokiStack instance using the openshift-network tenant configuration mode and provide fully-automatic, in-cluster authentication and authorization support for Network Observability. There are several ways you can install Loki. One way is by using the Red Hat OpenShift Container Platform web console Operator Hub.

Supported Log Store (AWS S3, Google Cloud Storage, Azure, Swift, Minio, OpenShift Data Foundation)

Red Hat OpenShift Container Platform 4.10+

Linux Kernel 4.18+


In the Red Hat OpenShift Container Platform web console, click Operators -> OperatorHub.

Choose  Loki Operator from the list of available Operators, and click Install.

Under Installation Mode, select All namespaces on the cluster.


Verify that you installed the Loki Operator. Visit the Operators â†’ Installed Operators page and look for Loki Operator.

Verify that Loki Operator is listed with Status as Succeeded in all the projects.


To uninstall Loki, refer to the uninstallation process that corresponds with the method you used to install Loki. You might have remaining ClusterRoles and ClusterRoleBindings, data stored in object store, and persistent volume that must be removed.
Creating a secret for Loki storage
The Loki Operator supports a few log storage options, such as AWS S3, Google Cloud Storage, Azure, Swift, Minio, OpenShift Data Foundation. The following example shows how to create a secret for AWS S3 storage. The secret created in this example, loki-s3, is referenced in "Creating a LokiStack resource". You can create this secret in the web console or CLI.

Using the web console, navigate to the Project -> All Projects dropdown and select Create Project. Name the project netobserv and click Create.

Navigate to the Import icon, +, in the top right corner. Paste your YAML file into the editor.


Once you create the secret, you should see it listed under Workloads -> Secrets in the web console.


Flow Collector API Reference

Flow Collector sample resource

Loki object storage
Creating a LokiStack custom resource
You can deploy a LokiStack custom resource (CR) by using the web console or OpenShift CLI (`oc`) to create a namespace, or new project.

Navigate to Operators -> Installed Operators, viewing All projects from the Project dropdown.

Look for Loki Operator. In the details, under Provided APIs, select LokiStack.

Click Create LokiStack.

Ensure the following fields are specified in either Form View or YAML view:

Click Create.
Creating a new group for the cluster-admin user role
Querying application logs for multiple namespaces as a cluster-admin user, where the sum total of characters of all of the namespaces in the cluster is greater than 5120, results in the error Parse error: input size too long (XXXX > 5120). For better control over access to logs in LokiStack, make the cluster-admin user a member of the cluster-admin group. If the cluster-admin group does not exist, create it and add the desired users to it.
Use the following procedure to create a new group for users with cluster-admin permissions.

Enter the following command to create a new group:

Enter the following command to add the desired user to the cluster-admin group:

Enter the following command to add cluster-admin user role to the group:
Custom admin group access
If you have a large deployment with a number of users who require broader permissions, you can create a custom group using the adminGroup field. Users who are members of any group specified in the adminGroups field of the LokiStack CR are considered admins. Admin users have access to all application logs in all namespaces, if they also get assigned the cluster-logging-application-view role.

apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  tenants:
    mode: openshift-network 1
    openshift:
      adminGroups: 2
      - cluster-admin
      - custom-admin-group 3
Custom admin groups are only available in this mode.

Entering an empty list [] value for this field disables admin groups.

Overrides the default groups (system:cluster-admins, cluster-admin, dedicated-admin)
Loki deployment sizing
Sizing for Loki follows the format of 1x.<size> where the value 1x is number of instances and <size> specifies performance capabilities.

It is not possible to change the number 1x for the deployment size.
LokiStack ingestion limits and health alerts
The LokiStack instance comes with default settings according to the configured size. It is possible to override some of these settings, such as the ingestion and query limits. You might want to update them if you get Loki errors showing up in the Console plugin, or in flowlogs-pipeline logs. An automatic alert in the web console notifies you when these limits are reached.

Here is an example of configured limits:

spec:
  limits:
    global:
      ingestion:
        ingestionBurstSize: 40
        ingestionRate: 20
        maxGlobalStreamsPerTenant: 25000
      queries:
        maxChunksPerQuery: 2000000
        maxEntriesLimitPerQuery: 10000
        maxQuerySeries: 3000
For more information about these settings, see the LokiStack API reference.
Enabling multi-tenancy in Network Observability
Multi-tenancy in the Network Observability Operator allows and restricts individual user access, or group access, to the flows stored in Loki. Access is enabled for project admins. Project admins who have limited access to some namespaces can access flows for only those namespaces.

You have installed at least Loki Operator version 5.7

You must be logged in as a project administrator


Authorize reading permission to user1 by running the following command:
Installing the Network Observability Operator
You can install the Network Observability Operator using the Red Hat OpenShift Container Platform web console Operator Hub. When you install the Operator,  it provides the FlowCollector custom resource definition (CRD). You can set specifications in the web console when you create the  FlowCollector.

The actual memory consumption of the Operator depends on your cluster size and the number of resources deployed. Memory consumption might need to be adjusted accordingly. For more information refer to "Network Observability controller manager pod runs out of memory" in the "Important Flow Collector configuration considerations" section.
If you choose to use Loki, install the Loki Operator version 5.7+.

You must have cluster-admin privileges.

One of the following supported architectures is required: amd64, ppc64le, arm64, or s390x.

Any CPU supported by Red Hat Enterprise Linux (RHEL) 9.

Must be configured with OVN-Kubernetes or OpenShift SDN as the main network plugin, and optionally using secondary interfaces, such as Multus and SR-IOV.


Additionally, this installation example uses the netobserv namespace, which is used across all components. You can optionally use a different namespace.
In the Red Hat OpenShift Container Platform web console, click Operators -> OperatorHub.

Choose  Network Observability Operator from the list of available Operators in the OperatorHub, and click Install.

Select the checkbox Enable Operator recommended cluster monitoring on this Namespace.

Navigate to Operators -> Installed Operators. Under Provided APIs for Network Observability, select the Flow Collector link.

Navigate to the Flow Collector tab, and click Create FlowCollector. Make the following selections in the form view:

Click Create.


To confirm this was successful, when you navigate to Observe you should see Network Traffic listed in the options.

In the absence of Application Traffic within the Red Hat OpenShift Container Platform cluster, default filters might show that there are "No results", which results in no visual flow. Beside the filter selections, select Clear all filters to see the flow.
Important Flow Collector configuration considerations
Once you create the FlowCollector instance, you can reconfigure it, but the pods are terminated and recreated again, which can be disruptive. Therefore, you can consider configuring the following options when creating the FlowCollector for the first time:

Configuring the Flow Collector resource with Kafka

Export enriched network flow data to Kafka or IPFIX

Configuring monitoring for SR-IOV interface traffic

Working with conversation tracking

Working with DNS tracking

Working with packet drops


For more general information about Flow Collector specifications and the Network Observability Operator architecture and resource use, see the following resources:

Flow Collector API Reference

Flow Collector sample resource

Resource considerations

Troubleshooting Network Observability controller manager pod runs out of memory

Network Observability architecture
Installing Kafka (optional)
The Kafka Operator is supported for large scale environments. Kafka provides high-throughput and low-latency data feeds for forwarding network flow data in a more resilient, scalable way. You can install the Kafka Operator as Red Hat AMQ Streams from the Operator Hub, just as the Loki Operator and Network Observability Operator were installed. Refer to "Configuring the FlowCollector resource with Kafka" to configure Kafka as a storage option.

To uninstall Kafka, refer to the uninstallation process that corresponds with the method you used to install.
Configuring the FlowCollector resource with Kafka.
Uninstalling the Network Observability Operator
You can uninstall the Network Observability Operator using the Red Hat OpenShift Container Platform web console Operator Hub, working in the Operators -> Installed Operators area.

Remove the FlowCollector custom resource.

Uninstall the Network Observability Operator.

Remove the FlowCollector custom resource definition (CRD).