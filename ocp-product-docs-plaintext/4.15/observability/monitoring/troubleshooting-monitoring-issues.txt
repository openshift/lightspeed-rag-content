Troubleshooting monitoring issues

Find troubleshooting steps for common issues with core platform and user-defined project monitoring.
Investigating why user-defined project metrics are unavailable
ServiceMonitor resources enable you to determine how to use the metrics exposed by a service in user-defined projects. Follow the steps outlined in this procedure if you have created a ServiceMonitor resource but cannot see any corresponding metrics in the Metrics UI.

You have access to the cluster as a user with the cluster-admin role.

You have installed the OpenShift CLI (oc).

You have enabled and configured monitoring for user-defined projects.

You have created a ServiceMonitor resource.


Check that the corresponding labels match in the service and ServiceMonitor resource configurations.

Inspect the logs for the Prometheus Operator in the openshift-user-workload-monitoring project.

Review the target status for your endpoint on the Metrics targets page in the Red Hat OpenShift Container Platform web console UI.

Configure debug level logging for the Prometheus Operator in the openshift-user-workload-monitoring project.


Creating a user-defined workload monitoring config map

See Specifying how a service is monitored for details on how to create a ServiceMonitor or PodMonitor resource

See Getting detailed information about metrics targets
Determining why Prometheus is consuming a lot of disk space
Developers can create labels to define attributes for metrics in the form of key-value pairs. The number of potential key-value pairs corresponds to the number of possible values for an attribute. An attribute that has an unlimited number of potential values is called an unbound attribute. For example, a customer_id attribute is unbound because it has an infinite number of possible values.

Every assigned key-value pair has a unique time series. The use of many unbound attributes in labels can result in an exponential increase in the number of time series created. This can impact Prometheus performance and can consume a lot of disk space.

You can use the following measures when Prometheus consumes a lot of disk:

Check the time series database (TSDB) status using the Prometheus HTTP API for more information about which labels are creating the most time series data. Doing so requires cluster administrator privileges.

Check the number of scrape samples that are being collected.

Reduce the number of unique time series that are created by reducing the number of unbound attributes that are assigned to user-defined metrics.

Enforce limits on the number of samples that can be scraped across user-defined projects. This requires cluster administrator privileges.


You have access to the cluster as a user with the cluster-admin cluster role.

You have installed the OpenShift CLI (oc).


In the Administrator perspective, navigate to Observe -> Metrics.

Enter a Prometheus Query Language (PromQL) query in the Expression field.
The following example queries help to identify high cardinality metrics that might result in high disk space consumption:

Investigate the number of unbound label values assigned to metrics with higher than expected scrape sample counts:

Review the TSDB status using the Prometheus HTTP API by following these steps when logged in as a
cluster administrator:


Accessing monitoring APIs by using the CLI

Setting a scrape sample limit for user-defined projects

Submitting a support case
Resolving the KubePersistentVolumeFillingUp alert firing for Prometheus
As a cluster administrator, you can resolve the KubePersistentVolumeFillingUp alert being triggered for Prometheus.

The critical alert fires when a persistent volume (PV) claimed by a prometheus-k8s-* pod in the openshift-monitoring project has less than 3% total space remaining. This can cause Prometheus to function abnormally.

There are two KubePersistentVolumeFillingUp alerts:

Critical alert:  The alert with the severity="critical" label is triggered when the mounted PV has less than 3% total space remaining.

Warning alert: The alert with the severity="warning" label is triggered when the mounted PV has less than 15% total space remaining and is expected to fill up within four days.
To address this issue, you can remove Prometheus time-series database (TSDB) blocks to create more space for the PV.

You have access to the cluster as a user with the cluster-admin cluster role.

You have installed the OpenShift CLI (oc).


List the size of all TSDB blocks, sorted from oldest to newest, by running the following command:

Identify which and how many blocks could be removed, then remove the blocks. The following example command removes the three oldest Prometheus TSDB blocks from the prometheus-k8s-0 pod:

Verify the usage of the mounted PV and ensure there is enough space available by running the following command: