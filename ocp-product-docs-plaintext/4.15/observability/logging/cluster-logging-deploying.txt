Installing Logging

You can deploy logging subsystem by installing the Red Hat OpenShift Logging Operator. The Red Hat OpenShift Logging Operator creates and manages the components of the logging stack.

Logging is provided as an installable component, with a distinct release cycle from the core Red Hat OpenShift Container Platform. The Red Hat OpenShift Container Platform Life Cycle Policy outlines release compatibility.
For new installations, use Vector and LokiStack. Elasticsearch and Fluentd are deprecated and are planned to be removed in a future release.
Installing the Red Hat OpenShift Logging Operator by using the web console
You can install the Red Hat OpenShift Logging Operator by using the Red Hat OpenShift Container Platform web console.

You have administrator permissions.

You have access to the Red Hat OpenShift Container Platform web console.


In the Red Hat OpenShift Container Platform web console, click Operators -> OperatorHub.

Type OpenShift Logging in the Filter by keyword box.

Choose  Red Hat OpenShift Logging from the list of available Operators, and click Install.

Select stable-5.y as the Update channel.

Select a Version.

Ensure that A specific namespace on the cluster is selected under Installation mode.

Ensure that Operator recommended namespace is openshift-logging under Installed Namespace.

Select an Update approval.

Select Enable or Disable for the Console plugin.

Click Install.


Verify that the Red Hat OpenShift Logging Operator is installed by switching to the Operators → Installed Operators page.

In the Status column, verify that you see green checkmarks with InstallSucceeded and the text Up to date.


An Operator might display a Failed status before the installation finishes. If the Operator install completes with an InstallSucceeded message, refresh the page.
If the Operator does not show as installed, choose one of the following troubleshooting options:

Go to the Operators → Installed Operators page, and inspect the Status column for any errors or failures.

Go to the Workloads → Pods page, and check the logs in any pods in the openshift-logging project that are reporting issues.
Creating a ClusterLogging object by using the web console
After you have installed the logging subsystem Operators, you must create a ClusterLogging custom resource to configure log storage, visualization, and the log collector for your cluster.

You have installed the Red Hat OpenShift Logging Operator.

You have access to the Red Hat OpenShift Container Platform web console Administrator perspective.


Navigate to the Custom Resource Definitions page.

On the Custom Resource Definitions page, click ClusterLogging.

On the Custom Resource Definition details page, select View Instances from the Actions menu.

On the ClusterLoggings page, click Create ClusterLogging.

In the collection section, select a Collector Implementation.

In the logStore section, select a type.

Click Create.
Installing the Red Hat OpenShift Logging Operator by using the CLI
You can use the OpenShift CLI (`oc`) to install the Red Hat OpenShift Logging Operator.

You have administrator permissions.

You have installed the OpenShift CLI (`oc`).


Create a Namespace object as a YAML file:

Apply the Namespace object by running the following command:

Create an OperatorGroup object as a YAML file:

Apply the OperatorGroup object by running the following command:

Create a Subscription object to subscribe the namespace to the Red Hat OpenShift Logging Operator:

Apply the subscription by running the following command:


Run the following command:

Observe the output and confirm that the Red Hat OpenShift Logging Operator exists in the namespace:
Creating a ClusterLogging object by using the CLI
This default logging subsystem configuration supports a wide array of environments. Review the topics on tuning and configuring components for information about modifications you can make.

You have installed the Red Hat OpenShift Logging Operator.

You have installed the Elasticsearch Operator for your log store.

You have installed the OpenShift CLI (`oc`).


Create a ClusterLogging object as a YAML file:


You can verify the installation by listing the pods in the openshift-logging project.

List the pods by running the following command:
Postinstallation tasks
After you have installed the Red Hat OpenShift Logging Operator, you can configure your deployment by creating and modifying a ClusterLogging custom resource (CR).

If you are not using the Elasticsearch log store, you can remove the internal Elasticsearch logStore and Kibana visualization components from the ClusterLogging custom resource (CR). Removing these components is optional but saves resources. See Removing unused components if you do not use the Elasticsearch log store.
About the ClusterLogging custom resource
To make changes to your logging subsystem environment, create and modify the ClusterLogging custom resource (CR).

apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance 1
  namespace: openshift-logging 2
spec:
  managementState: Managed 3
# ...
The CR name must be instance.

The CR must be installed to the openshift-logging namespace.

The Red Hat OpenShift Logging Operator management state. When the state is set to unmanaged, the Operator is in an unsupported state and does not receive updates.
Configuring log storage
You can configure which log storage type your logging subsystem uses by modifying the ClusterLogging custom resource (CR).

You have administrator permissions.

You have installed the OpenShift CLI (`oc`).

You have installed the Red Hat OpenShift Logging Operator and an internal log store that is either the LokiStack or Elasticsearch.

You have created a ClusterLogging CR.


The Logging subsystem 5.9 release does not contain an updated version of the Elasticsearch Operator. If you currently use the Elasticsearch Operator released with Logging subsystem 5.8, it will continue to work with Logging subsystem until the EOL of Logging subsystem 5.8. As an alternative to using the Elasticsearch Operator to manage the default log storage, you can use the Loki Operator. For more information on the Logging subsystem lifecycle dates, see Platform Agnostic Operators.
Modify the ClusterLogging CR logStore spec:

Apply the ClusterLogging CR by running the following command:
Configuring the log collector
You can configure which log collector type your logging subsystem uses by modifying the ClusterLogging custom resource (CR).

Fluentd is deprecated and is planned to be removed in a future release. Red Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to Fluentd, you can use Vector instead.
You have administrator permissions.

You have installed the OpenShift CLI (`oc`).

You have installed the Red Hat OpenShift Logging Operator.

You have created a ClusterLogging CR.


Modify the ClusterLogging CR collection spec:

Apply the ClusterLogging CR by running the following command:
Configuring the log visualizer
You can configure which log visualizer type your logging subsystem uses by modifying the ClusterLogging custom resource (CR).

You have administrator permissions.

You have installed the OpenShift CLI (`oc`).

You have installed the Red Hat OpenShift Logging Operator.

You have created a ClusterLogging CR.


If you want to use the Red Hat OpenShift Container Platform web console for visualization, you must enable the logging Console Plugin. See the documentation about "Log visualization with the web console".
Modify the ClusterLogging CR visualization spec:

Apply the ClusterLogging CR by running the following command:
Allowing traffic between projects when network isolation is enabled
Your cluster network plugin might enforce network isolation. If so, you must allow network traffic between the projects that contain the operators deployed by OpenShift Logging.

Network isolation blocks network traffic between pods or services that are in different projects. The logging subsystem installs the OpenShift Elasticsearch Operator in the openshift-operators-redhat project and the Red Hat OpenShift Logging Operator in the openshift-logging project. Therefore, you must allow traffic between these two projects.

Red Hat OpenShift Container Platform offers two supported choices for the network plugin, OpenShift SDN and OVN-Kubernetes. These two providers implement various network isolation policies.

OpenShift SDN has three modes:


network policy
This is the default mode. If no policy is defined, it allows all traffic. However, if a user defines a policy, they typically start by denying all traffic and then adding exceptions. This process might break applications that are running in different projects. Therefore, explicitly configure the policy to allow traffic to egress from one logging-related project to the other.
subnet
This mode allows all traffic. It does not enforce network isolation. No action is needed.


OVN-Kubernetes always uses a network policy. Therefore, as with OpenShift SDN, you must configure the policy to allow traffic to egress from one logging-related project to the other.

If you are using OpenShift SDN in multitenant mode, join the two projects. For example:

Otherwise, for OpenShift SDN in network policy mode and OVN-Kubernetes, perform the following actions: