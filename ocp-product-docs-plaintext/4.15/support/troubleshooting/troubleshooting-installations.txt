Troubleshooting installations

Determining where installation issues occur
When troubleshooting "Red Hat OpenShift Container Platform" installation issues, you can monitor installation logs to determine at which stage issues occur. Then, retrieve diagnostic data relevant to that stage.

"Red Hat OpenShift Container Platform" installation proceeds through the following stages:

Ignition configuration files are created.

The bootstrap machine boots and starts hosting the remote resources required for the control plane machines to boot.

The control plane machines fetch the remote resources from the bootstrap machine and finish booting.

The control plane machines use the bootstrap machine to form an etcd cluster.

The bootstrap machine starts a temporary Kubernetes control plane using the new etcd cluster.

The temporary control plane schedules the production control plane to the control plane machines.

The temporary control plane shuts down and passes control to the production control plane.

The bootstrap machine adds "Red Hat OpenShift Container Platform" components into the production control plane.

The installation program shuts down the bootstrap machine.

The control plane sets up the worker nodes.

The control plane installs additional services in the form of a set of Operators.

The cluster downloads and configures remaining components needed for the day-to-day operation, including the creation of worker machines in supported environments.
User-provisioned infrastructure installation considerations
The default installation method uses installer-provisioned infrastructure. With installer-provisioned infrastructure clusters, "Red Hat OpenShift Container Platform" manages all aspects of the cluster, including the operating system itself. If possible, use this feature to avoid having to provision and maintain the cluster infrastructure.

You can alternatively install "Red Hat OpenShift Container Platform" {product-version} on infrastructure that you provide. If you use this installation method, follow user-provisioned infrastructure installation documentation carefully. Additionally, review the following considerations before the installation:

Check the Red Hat Enterprise Linux (RHEL) Ecosystem to determine the level of Red Hat Enterprise Linux CoreOS (RHCOS) support provided for your chosen server hardware or virtualization technology.

Many virtualization and cloud environments require agents to be installed on guest operating systems. Ensure that these agents are installed as a containerized workload deployed through a daemon set.

Install cloud provider integration if you want to enable features such as dynamic storage, on-demand service routing, node hostname to Kubernetes hostname resolution, and cluster autoscaling.

A provider-specific Machine API implementation is required if you want to use machine sets or autoscaling to automatically provision "Red Hat OpenShift Container Platform" cluster nodes.

Check whether your chosen cloud provider offers a method to inject Ignition configuration files into hosts as part of their initial deployment. If they do not, you will need to host Ignition configuration files by using an HTTP server. The steps taken to troubleshoot Ignition configuration file issues will differ depending on which of these two methods is deployed.

Storage needs to be manually provisioned if you want to leverage optional framework components such as the embedded container registry, Elasticsearch, or Prometheus. Default storage classes are not defined in user-provisioned infrastructure installations unless explicitly configured.

A load balancer is required to distribute API requests across all control plane nodes in highly available "Red Hat OpenShift Container Platform" environments. You can use any TCP-based load balancing solution that meets "Red Hat OpenShift Container Platform" DNS routing and port requirements.
Checking a load balancer configuration before "Red Hat OpenShift Container Platform" installation
Check your load balancer configuration prior to starting an "Red Hat OpenShift Container Platform" installation.

You have configured an external load balancer of your choosing, in preparation for an "Red Hat OpenShift Container Platform" installation. The following example is based on a Red Hat Enterprise Linux (RHEL) host using HAProxy to provide load balancing services to a cluster.

You have configured DNS in preparation for an "Red Hat OpenShift Container Platform" installation.

You have SSH access to your load balancer.


Check that the haproxy systemd service is active:

Verify that the load balancer is listening on the required ports. The following example references ports 80, 443, 6443, and 22623.

Check that the wildcard DNS record resolves to the load balancer:
Specifying "Red Hat OpenShift Container Platform" installer log levels
By default, the "Red Hat OpenShift Container Platform" installer log level is set to info. If more detailed logging is required when diagnosing a failed "Red Hat OpenShift Container Platform" installation, you can increase the openshift-install log level to debug when starting the installation again.

You have access to the installation host.


Set the installation log level to debug when initiating the installation:
Troubleshooting openshift-install command issues
If you experience issues running the openshift-install command, check the following:

The installation has been initiated within 24 hours of Ignition configuration file creation. The Ignition files are created when the following command is run:

The install-config.yaml file is in the same directory as the installer. If an alternative installation path is declared by using the ./openshift-install --dir option, verify that the install-config.yaml file exists within that directory.
Monitoring installation progress
You can monitor high-level installation, bootstrap, and control plane logs as an "Red Hat OpenShift Container Platform" installation progresses. This provides greater visibility into how an installation progresses and helps identify the stage at which an installation failure occurs.

You have access to the cluster as a user with the cluster-admin cluster role.

You have installed the OpenShift CLI (oc).

You have SSH access to your hosts.

You have the fully qualified domain names of the bootstrap and control plane nodes.


Watch the installation log as the installation progresses:

Monitor the bootkube.service journald unit log on the bootstrap node, after it has booted. This provides visibility into the bootstrapping of the first control plane. Replace <bootstrap_fqdn> with the bootstrap node's fully qualified domain name:

Monitor kubelet.service journald unit logs on control plane nodes, after they have booted. This provides visibility into control plane node agent activity.

Monitor crio.service journald unit logs on control plane nodes, after they have booted. This provides visibility into control plane node CRI-O container runtime activity.
Gathering bootstrap node diagnostic data
When experiencing bootstrap-related issues, you can gather bootkube.service journald unit logs and container logs from the bootstrap node.

You have SSH access to your bootstrap node.

You have the fully qualified domain name of the bootstrap node.

If you are hosting Ignition configuration files by using an HTTP server, you must have the HTTP server's fully qualified domain name and the port number. You must also have SSH access to the HTTP host.


If you have access to the bootstrap node's console, monitor the console until the node reaches the login prompt.

Verify the Ignition file configuration.

Verify the availability of the bootstrap node's assigned storage device.

Verify that the bootstrap node has been assigned an IP address from the DHCP server.

Collect bootkube.service journald unit logs from the bootstrap node. Replace <bootstrap_fqdn> with the bootstrap node's fully qualified domain name:

Collect logs from the bootstrap node containers.

If the bootstrap process fails, verify the following.
Investigating control plane node installation issues
If you experience control plane node installation issues, determine the control plane node "Red Hat OpenShift Container Platform" software defined network (SDN), and network Operator status. Collect kubelet.service, crio.service journald unit logs, and control plane node container logs for visibility into control plane node agent, CRI-O container runtime, and pod activity.

You have access to the cluster as a user with the cluster-admin role.

You have installed the OpenShift CLI (oc).

You have SSH access to your hosts.

You have the fully qualified domain names of the bootstrap and control plane nodes.

If you are hosting Ignition configuration files by using an HTTP server, you must have the HTTP server's fully qualified domain name and the port number. You must also have SSH access to the HTTP host.


If you have access to the console for the control plane node, monitor the console until the node reaches the login prompt. During the installation, Ignition log messages are output to the console.

Verify Ignition file configuration.

Check the availability of the storage device assigned to the control plane node.

Verify that the control plane node has been assigned an IP address from the DHCP server.

Determine control plane node status.

Determine "Red Hat OpenShift Container Platform" SDN status.

Determine cluster network configuration status.

Monitor kubelet.service journald unit logs on control plane nodes, after they have booted. This provides visibility into control plane node agent activity.

Retrieve crio.service journald unit logs on control plane nodes, after they have booted. This provides visibility into control plane node CRI-O container runtime activity.

Collect logs from specific subdirectories under /var/log/ on control plane nodes.

Review control plane node container logs using SSH.

If you experience control plane node configuration issues, verify that the MCO, MCO endpoint, and DNS record are functioning. The Machine Config Operator (MCO) manages operating system configuration during the installation procedure. Also verify system clock accuracy and certificate validity.
Investigating etcd installation issues
If you experience etcd issues during installation, you can check etcd pod status and collect etcd pod logs. You can also verify etcd DNS records and check DNS availability on control plane nodes.

You have access to the cluster as a user with the cluster-admin role.

You have installed the OpenShift CLI (oc).

You have SSH access to your hosts.

You have the fully qualified domain names of the control plane nodes.


Check the status of etcd pods.

If any of the pods listed by the previous commands are not showing a Running or a Completed status, gather diagnostic information for the pod.

If the API is not functional, review etcd pod and container logs on each control plane node by using SSH instead. Replace <master-node>.<cluster_name>.<base_domain> with appropriate values.

Validate primary and secondary DNS server connectivity from control plane nodes.
Investigating control plane node kubelet and API server issues
To investigate control plane node kubelet and API server issues during installation, check DNS, DHCP, and load balancer functionality. Also, verify that certificates have not expired.

You have access to the cluster as a user with the cluster-admin role.

You have installed the OpenShift CLI (oc).

You have SSH access to your hosts.

You have the fully qualified domain names of the control plane nodes.


Verify that the API server's DNS record directs the kubelet on control plane nodes to https://api-int.<cluster_name>.<base_domain>:6443. Ensure that the record references the load balancer.

Ensure that the load balancer's port 6443 definition references each control plane node.

Check that unique control plane node hostnames have been provided by DHCP.

Inspect the kubelet.service journald unit logs on each control plane node.

Check for certificate expiration messages in the control plane node kubelet logs.
Investigating worker node installation issues
If you experience worker node installation issues, you can review the worker node status. Collect kubelet.service, crio.service journald unit logs and the worker node container logs for visibility into the worker node agent, CRI-O container runtime and pod activity. Additionally, you can check the Ignition file and Machine API Operator functionality. If worker node postinstallation configuration fails, check Machine Config Operator (MCO) and DNS functionality. You can also verify system clock synchronization between the bootstrap, master, and worker nodes, and validate certificates.

You have access to the cluster as a user with the cluster-admin role.

You have installed the OpenShift CLI (oc).

You have SSH access to your hosts.

You have the fully qualified domain names of the bootstrap and worker nodes.

If you are hosting Ignition configuration files by using an HTTP server, you must have the HTTP server's fully qualified domain name and the port number. You must also have SSH access to the HTTP host.


If you have access to the worker node's console, monitor the console until the node reaches the login prompt. During the installation, Ignition log messages are output to the console.

Verify Ignition file configuration.

Check the availability of the worker node's assigned storage device.

Verify that the worker node has been assigned an IP address from the DHCP server.

Determine worker node status.

Unlike control plane nodes, worker nodes are deployed and scaled using the Machine API Operator. Check the status of the Machine API Operator.

Monitor kubelet.service journald unit logs on worker nodes, after they have booted. This provides visibility into worker node agent activity.

Retrieve crio.service journald unit logs on worker nodes, after they have booted. This provides visibility into worker node CRI-O container runtime activity.

Collect logs from specific subdirectories under /var/log/ on worker nodes.

Review worker node container logs using SSH.

If you experience worker node configuration issues, verify that the MCO, MCO endpoint, and DNS record are functioning. The Machine Config Operator (MCO) manages operating system configuration during the installation procedure. Also verify system clock accuracy and certificate validity.
Querying Operator status after installation
You can check Operator status at the end of an installation. Retrieve diagnostic data for Operators that do not become available. Review logs for any Operator pods that are listed as Pending or have an error status. Validate base images used by problematic pods.

You have access to the cluster as a user with the cluster-admin role.

You have installed the OpenShift CLI (oc).


Check that cluster Operators are all available at the end of an installation.

Verify that all of the required certificate signing requests (CSRs) are approved. Some nodes might not move to a Ready status and some cluster Operators might not become available if there are pending CSRs.

View Operator events:

Review Operator pod status within the Operator's namespace:

Obtain a detailed description for pods that do not have Running status:

Inspect pod logs:

When experiencing pod base image related issues, review base image status.
Gathering logs from a failed installation
If you gave an SSH key to your installation program, you can gather data about your failed installation.

You use a different command to gather logs about an unsuccessful installation than to gather logs from a running cluster. If you must gather logs from a running cluster, use the oc adm must-gather command.
Your "Red Hat OpenShift Container Platform" installation failed before the bootstrap process finished. The bootstrap node is running and accessible through SSH.

The ssh-agent process is active on your computer, and you provided the same SSH key to both the ssh-agent process and the installation program.

If you tried to install a cluster on infrastructure that you provisioned, you must have the fully qualified domain names of the bootstrap and control plane nodes.


Generate the commands that are required to obtain the installation logs from
the bootstrap and control plane machines:
Additional resources
See Installation process for more details on "Red Hat OpenShift Container Platform" installation types and process.