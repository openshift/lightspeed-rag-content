Configuring PTP devices

The PTP Operator adds the NodePtpDevice.ptp.openshift.io custom resource definition (CRD) to Red Hat OpenShift Container Platform.

When installed, the PTP Operator searches your cluster for PTP-capable network devices on each node. It creates and updates a NodePtpDevice custom resource (CR) object for each node that provides a compatible PTP-capable network device.
Installing the PTP Operator using the CLI
As a cluster administrator, you can install the Operator by using the CLI.

A cluster installed on bare-metal hardware with nodes that have hardware that supports PTP.

Install the OpenShift CLI (oc).

Log in as a user with cluster-admin privileges.


Create a namespace for the PTP Operator.

Create an Operator group for the PTP Operator.

Subscribe to the PTP Operator.

To verify that the Operator is installed, enter the following command:
Installing the PTP Operator by using the web console
As a cluster administrator, you can install the PTP Operator by using the web console.

You have to create the namespace and Operator group as mentioned in the previous section.
Install the PTP Operator using the Red Hat OpenShift Container Platform web console:

Optional: Verify that the PTP Operator installed successfully:
Discovering PTP capable network devices in your cluster
To return a complete list of PTP capable network devices in your cluster, run the following command:
Using hardware-specific NIC features with the PTP Operator
NIC hardware with built-in PTP capabilities sometimes require device-specific configuration. You can use hardware-specific NIC features for supported hardware with the PTP Operator by configuring a plugin in the PtpConfig custom resource (CR). The linuxptp-daemon service uses the named parameters in the plugin stanza to start linuxptp processes (ptp4l and phc2sys) based on the specific hardware configuration.

In Red Hat OpenShift Container Platform 4.15, the Intel E810 NIC is supported with a PtpConfig plugin.
Configuring linuxptp services as a grandmaster clock
You can configure the linuxptp services (ptp4l, phc2sys, ts2phc) as grandmaster clock (T-GM) by creating a PtpConfig custom resource (CR) that configures the host NIC.

The ts2phc utility allows you to synchronize the system clock with the PTP grandmaster clock so that the node can stream precision clock signal to downstream PTP ordinary clocks and boundary clocks.

Use the following example PtpConfig CR as the basis to configure linuxptp services as T-GM for an Intel Westport Channel E810-XXVDA4T network interface.

To configure PTP fast events, set appropriate values for ptp4lOpts, ptp4lConf, and ptpClockThreshold. ptpClockThreshold is used only when events are enabled. See "Configuring the PTP fast event notifications publisher" for more information.
For T-GM clocks in production environments, install an Intel E810 Westport Channel NIC in the bare-metal cluster host.

Install the OpenShift CLI (oc).

Log in as a user with cluster-admin privileges.

Install the PTP Operator.


Create the PtpConfig CR. For example:


Check that the PtpConfig profile is applied to the node.
Configuring linuxptp services as a grandmaster clock for dual E810 Westport Channel NICs
You can configure the linuxptp services (ptp4l, phc2sys, ts2phc) as grandmaster clock (T-GM) for dual E810 Westport Channel NICs by creating a PtpConfig custom resource (CR) that configures the host NICs.

For distributed RAN (D-RAN) use cases, you can configure PTP for dual NICs as follows:

NIC one is synced to the global navigation satellite system (GNSS) time source.

NIC two is synced to the 1PPS timing output provided by NIC one. This configuration is provided by the PTP hardware plugin in the PtpConfig CR.


The dual NIC PTP T-GM configuration uses a single instance of ptp4l and one ts2phc process reporting two ts2phc instances, one for each NIC. The host system clock is synchronized from the NIC that is connected to the GNSS time source.

Use the following example PtpConfig CR as the basis to configure linuxptp services as T-GM for dual Intel Westport Channel E810-XXVDA4T network interfaces.

To configure PTP fast events, set appropriate values for ptp4lOpts, ptp4lConf, and ptpClockThreshold. ptpClockThreshold is used only when events are enabled. See "Configuring the PTP fast event notifications publisher" for more information.
For T-GM clocks in production environments, install two Intel E810 Westport Channel NICs in the bare-metal cluster host.

Install the OpenShift CLI (oc).

Log in as a user with cluster-admin privileges.

Install the PTP Operator.


Create the PtpConfig CR. For example:


Check that the PtpConfig profile is applied to the node.


Configuring the PTP fast event notifications publisher


Grandmaster clock PtpConfig configuration reference
The following reference information describes the configuration options for the PtpConfig custom resource (CR) that configures the linuxptp services (ptp4l, phc2sys, ts2phc) as a grandmaster clock.
Grandmaster clock class sync state reference
The following table describes the PTP grandmaster clock (T-GM) gm.ClockClass states. Clock class states categorize T-GM clocks based on their accuracy and stability with regard to the Primary Reference Time Clock (PRTC) or other timing source.

Holdover specification is the amount of time a PTP clock can maintain synchronization without receiving updates from the primary time source.


For more information, see "Phase/time traceability information", ITU-T G.8275.1/Y.1369.1 Recommendations.
Intel Westport Channel E810 hardware configuration reference
Use this information to understand how to use the Intel E810-XXVDA4T hardware plugin to configure the E810 network interface as PTP grandmaster clock. Hardware pin configuration determines how the network interface interacts with other components and devices in the system. The E810-XXVDA4T NIC has four connectors for external 1PPS signals: SMA1, SMA2, U.FL1, and U.FL2.


SMA1 and U.FL1 connectors share channel one. SMA2 and U.FL2 connectors share channel two.
Set spec.profile.plugins.e810.ublxCmds parameters to configure the GNSS clock in the PtpConfig custom resource (CR). Each of these ublxCmds stanzas correspond to a configuration that is applied to the host NIC by using ubxtool commands. For example:

ublxCmds:
  - args: #ubxtool -P 29.20 -z CFG-HW-ANT_CFG_VOLTCTRL,1
      - "-P"
      - "29.20"
      - "-z"
      - "CFG-HW-ANT_CFG_VOLTCTRL,1"
    reportOutput: false
The following table describes the equivalent ubxtool commands:


The E810 plugin implements the following interfaces:


The E810 plugin has the following structs and variables:
Dual E810 Westport Channel NIC configuration reference
Use this information to understand how to use the Intel E810-XXVDA4T hardware plugin to configure a pair of E810 network interfaces as PTP grandmaster clock (T-GM).

Before you configure the dual NIC cluster host, you must connect the two NICs with an SMA1 cable using the 1PPS faceplace connections.

When you configure a dual NIC T-GM, you need to compensate for the 1PPS signal delay that occurs when you connect the NICs using the SMA1 connection ports. Various factors such as cable length, ambient temperature, and component and manufacturing tolerances can affect the signal delay. To compensate for the delay, you must calculate the specific value that you use to offset the signal delay.
Configuring linuxptp services as a boundary clock
You can configure the linuxptp services (ptp4l, phc2sys) as boundary clock by creating a PtpConfig custom resource (CR) object.

Use the following example PtpConfig CR as the basis to configure linuxptp services as the boundary clock for your particular hardware and environment. This example CR does not configure PTP fast events. To configure PTP fast events, set appropriate values for ptp4lOpts, ptp4lConf, and ptpClockThreshold. ptpClockThreshold is used only when events are enabled. See "Configuring the PTP fast event notifications publisher" for more information.
Install the OpenShift CLI (oc).

Log in as a user with cluster-admin privileges.

Install the PTP Operator.


Create the following PtpConfig CR, and then save the YAML in the boundary-clock-ptp-config.yaml file.

Create the CR by running the following command:


Check that the PtpConfig profile is applied to the node.


Configuring FIFO priority scheduling for PTP hardware

Configuring the PTP fast event notifications publisher


Configuring linuxptp services as boundary clocks for dual NIC hardware
Precision Time Protocol (PTP) hardware with dual NIC configured as boundary clocks is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of Red Hat Technology Preview features, see Technology Preview Features Support Scope.
You can configure the linuxptp services (ptp4l, phc2sys) as boundary clocks for dual NIC hardware by creating a PtpConfig custom resource (CR) object for each NIC.

Dual NIC hardware allows you to connect each NIC to the same upstream leader clock with separate ptp4l instances for each NIC feeding the downstream clocks.

Install the OpenShift CLI (oc).

Log in as a user with cluster-admin privileges.

Install the PTP Operator.


Create two separate PtpConfig CRs, one for each NIC, using the reference CR in "Configuring linuxptp services as a boundary clock" as the basis for each CR. For example:

Create the dual NIC PtpConfig CRs by running the following commands:


Check that the PTP Operator has applied the PtpConfig CRs for both NICs. Examine the logs for the linuxptp daemon corresponding to the node that has the dual NIC hardware installed. For example, run the following command:
Configuring linuxptp services as an ordinary clock
You can configure linuxptp services (ptp4l, phc2sys) as ordinary clock by creating a PtpConfig custom resource (CR) object.

Use the following example PtpConfig CR as the basis to configure linuxptp services as an ordinary clock for your particular hardware and environment. This example CR does not configure PTP fast events. To configure PTP fast events, set appropriate values for ptp4lOpts, ptp4lConf, and ptpClockThreshold. ptpClockThreshold is required only when events are enabled. See "Configuring the PTP fast event notifications publisher" for more information.
Install the OpenShift CLI (oc).

Log in as a user with cluster-admin privileges.

Install the PTP Operator.


Create the following PtpConfig CR, and then save the YAML in the ordinary-clock-ptp-config.yaml file.

Create the PtpConfig CR by running the following command:


Check that the PtpConfig profile is applied to the node.


Configuring FIFO priority scheduling for PTP hardware

Configuring the PTP fast event notifications publisher


Intel Columbiaville E800 series NIC as PTP ordinary clock reference
The following table describes the changes that you must make to the reference PTP configuration to use Intel Columbiaville E800 series NICs as ordinary clocks. Make the changes in a PtpConfig custom resource (CR) that you apply to the cluster.


For phc2sysOpts, -m prints messages to stdout. The linuxptp-daemon DaemonSet parses the logs and generates Prometheus metrics.
For a complete example CR that configures linuxptp services as an ordinary clock with PTP fast events, see Configuring linuxptp services as ordinary clock.
Configuring FIFO priority scheduling for PTP hardware
In telco or other deployment types that require low latency performance, PTP daemon threads run in a constrained CPU footprint alongside the rest of the infrastructure components. By default, PTP threads run with the SCHED_OTHER policy. Under high load, these threads might not get the scheduling latency they require for error-free operation.

To mitigate against potential scheduling latency errors, you can configure the PTP Operator linuxptp services to allow threads to run with a SCHED_FIFO policy. If SCHED_FIFO is set for a PtpConfig CR, then ptp4l and phc2sys will run in the parent container under chrt with a priority set by the ptpSchedulingPriority field of the PtpConfig CR.

Setting ptpSchedulingPolicy is optional, and is only required if you are experiencing latency errors.
Edit the PtpConfig CR profile:

Change the ptpSchedulingPolicy and ptpSchedulingPriority fields:

Save and exit to apply the changes to the PtpConfig CR.


Get the name of the linuxptp-daemon pod and corresponding node where the PtpConfig CR has been applied:

Check that the ptp4l process is running with the updated chrt FIFO priority:
Configuring log filtering for linuxptp services
The linuxptp daemon generates logs that you can use for debugging purposes. In telco or other deployment types that feature a limited storage capacity, these logs can add to the storage demand.

To reduce the number log messages, you can configure the PtpConfig custom resource (CR) to exclude log messages that report the master offset value. The master offset log message reports the difference between the current node's clock and the master clock in nanoseconds.

Install the OpenShift CLI (oc).

Log in as a user with cluster-admin privileges.

Install the PTP Operator.


Edit the PtpConfig CR:

In spec.profile, add the ptpSettings.logReduce specification and set the value to true:

Save and exit to apply the changes to the PtpConfig CR.


Get the name of the linuxptp-daemon pod and corresponding node where the PtpConfig CR has been applied:

Verify that master offset messages are excluded from the logs by running the following command:
Troubleshooting common PTP Operator issues
Troubleshoot common problems with the PTP Operator by performing the following steps.

Install the Red Hat OpenShift Container Platform CLI (oc).

Log in as a user with cluster-admin privileges.

Install the PTP Operator on a bare-metal cluster with hosts that support PTP.


Check the Operator and operands are successfully deployed in the cluster for the configured nodes.

Check that supported hardware is found in the cluster.

Check the available PTP network interfaces for a node:

Check that the PTP interface is successfully synchronized to the primary clock by accessing the linuxptp-daemon pod for the corresponding node.

For GNSS-sourced grandmaster clocks, verify that the in-tree NIC ice driver is correct by running the following command, for example:

For GNSS-sourced grandmaster clocks, verify that the linuxptp-daemon container is receiving signal from the GNSS antenna.
If the container is not receiving the GNSS signal, the /dev/gnss0 file is not populated.
To verify, run the following command:
Collecting PTP Operator data
You can use the oc adm must-gather command to collect information about your cluster, including features and objects associated with PTP Operator.

You have access to the cluster as a user with the cluster-admin role.

You have installed the OpenShift CLI (`oc`).

You have installed the PTP Operator.


To collect PTP Operator data with must-gather, you must specify the PTP Operator must-gather image.