Running tasks in pods using jobs

A job executes a task in your Red Hat OpenShift Container Platform cluster.

A job tracks the overall progress of a task and updates its status with information about active, succeeded, and failed pods. Deleting a job will clean up any pod replicas it created. Jobs are part of the Kubernetes API, which can be managed with oc commands like other object types.

apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  parallelism: 1    1
  completions: 1    2
  activeDeadlineSeconds: 1800 3
  backoffLimit: 6   4
  template:         5
    metadata:
      name: pi
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: OnFailure    6
#...
The pod replicas a job should run in parallel.

Successful pod completions are needed to mark a job completed.

The maximum duration the job can run.

The number of retries for a job.

The template for the pod the controller creates.

The restart policy of the pod.


Jobs in the Kubernetes documentation
Understanding jobs and cron jobs
A job tracks the overall progress of a task and updates its status with information about active, succeeded, and failed pods. Deleting a job cleans up any pods it created. Jobs are part of the Kubernetes API, which can be managed with oc commands like other object types.

There are two possible resource types that allow creating run-once objects in Red Hat OpenShift Container Platform:


Job
A regular job is a run-once object that creates a task and ensures the job finishes.
Cron job
A job can be scheduled to run multiple times, using a cron job.


Understanding how to create jobs
Both resource types require a job configuration that consists of the following key parts:

A pod template, which describes the pod that Red Hat OpenShift Container Platform creates.

The parallelism parameter, which specifies how many pods running in parallel at any point in time should execute a job.

The completions parameter, specifying how many successful pod completions are needed to finish a job.
Understanding how to set a maximum duration for jobs
When defining a job, you can define its maximum duration by setting the activeDeadlineSeconds field. It is specified in seconds and is not set by default. When not set, there is no maximum duration enforced.

The maximum duration is counted from the time when a first pod gets scheduled in the system, and defines how long a job can be active. It tracks overall time of an execution. After reaching the specified timeout, the job is terminated by Red Hat OpenShift Container Platform.
Understanding how to set a job back off policy for pod failure
A job can be considered failed, after a set amount of retries due to a logical error in configuration or other similar reasons. Failed pods associated with the job are recreated by the controller with an exponential back off delay (10s, 20s, 40s â€¦) capped at six minutes. The limit is reset if no new failed pods appear between controller checks.

Use the spec.backoffLimit parameter to set the number of retries for a job.
Understanding how to configure a cron job to remove artifacts
Cron jobs can leave behind artifact resources such as jobs or pods.  As a user it is important to configure history limits so that old jobs and their pods are properly cleaned.  There are two fields within cron job's spec responsible for that:

.spec.successfulJobsHistoryLimit. The number of successful finished jobs to retain (defaults to 3).

.spec.failedJobsHistoryLimit. The number of failed finished jobs to retain (defaults to 1).


Delete cron jobs that you no longer need:

You can suspend further executions by setting the spec.suspend to true.  All subsequent executions are suspended until you reset to false.
Known limitations
The job specification restart policy only applies to the pods, and not the job controller. However, the job controller is hard-coded to keep retrying jobs to completion.

As such, restartPolicy: Never or --restart=Never results in the same behavior as restartPolicy: OnFailure or --restart=OnFailure. That is, when a job fails it is restarted automatically until it succeeds (or is manually discarded). The policy only sets which subsystem performs the restart.

With the Never policy, the job controller performs the restart. With each attempt, the job controller increments the number of failures in the job status and create new pods. This means that with each failed attempt, the number of pods increases.

With the OnFailure policy, kubelet performs the restart. Each attempt does not increment the number of failures in the job status. In addition, kubelet will retry failed jobs starting pods on the same nodes.
Creating jobs
You create a job in Red Hat OpenShift Container Platform by creating a job object.

To create a job:

Create a YAML file similar to the following:

Create the job:


You can also create and launch a job from a single command using oc create job. The following command creates and launches a job similar to the one specified in the previous example:

$ oc create job pi --image=perl -- perl -Mbignum=bpi -wle 'print bpi(2000)'
Creating cron jobs
You create a cron job in Red Hat OpenShift Container Platform by creating a job object.

To create a cron job:

Create a YAML file similar to the following:

Create the cron job:


You can also create and launch a cron job from a single command using oc create cronjob. The following command creates and launches a cron job similar to the one specified in the previous example:

$ oc create cronjob pi --image=perl --schedule='*/1 * * * *' -- perl -Mbignum=bpi -wle 'print bpi(2000)'
With oc create cronjob, the --schedule option accepts schedules in cron format.