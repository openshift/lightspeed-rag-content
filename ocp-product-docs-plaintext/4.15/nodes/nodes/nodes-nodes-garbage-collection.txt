Freeing node resources using garbage collection

As an administrator, you can use Red Hat OpenShift Container Platform to ensure that your nodes are running efficiently by freeing up resources through garbage collection.

The Red Hat OpenShift Container Platform node performs two types of garbage collection:

Container garbage collection: Removes terminated containers.

Image garbage collection: Removes images not referenced by any running pods.
Understanding how terminated containers are removed through garbage collection
Container garbage collection removes terminated containers by using eviction thresholds.

When eviction thresholds are set for garbage collection, the node tries to keep any container for any pod accessible from the API. If the pod has been deleted, the containers will be as well. Containers are preserved as long the pod is not deleted and the eviction threshold is not reached. If the node is under disk pressure, it will remove containers and their logs will no longer be accessible using oc logs.

eviction-soft - A soft eviction threshold pairs an eviction threshold with a required administrator-specified grace period.

eviction-hard - A hard eviction threshold has no grace period, and if observed, Red Hat OpenShift Container Platform takes immediate action.


The following table lists the eviction thresholds:


For evictionHard you must specify all of these parameters.  If you do not specify all parameters, only the specified parameters are applied and the garbage collection will not function properly.
If a node is oscillating above and below a soft eviction threshold, but not exceeding its associated grace period, the corresponding node would constantly oscillate between true and false. As a consequence, the scheduler could make poor scheduling decisions.

To protect against this oscillation, use the eviction-pressure-transition-period flag to control how long Red Hat OpenShift Container Platform must wait before transitioning out of a pressure condition. Red Hat OpenShift Container Platform will not set an eviction threshold as being met for the specified pressure condition for the period specified before toggling the condition back to false.
Understanding how images are removed through garbage collection
Image garbage collection removes images that are not referenced by any running pods.

Red Hat OpenShift Container Platform determines which images to remove from a node based on the disk usage that is reported by cAdvisor.

The policy for image garbage collection is based on two conditions:

The percent of disk usage (expressed as an integer) which triggers image
garbage collection. The default is 85.

The percent of disk usage (expressed as an integer) to which image garbage
collection attempts to free. Default is 80.


For image garbage collection, you can modify any of the following variables using a custom resource.


Two lists of images are retrieved in each garbage collector run:

A list of images currently running in at least one pod.

A list of images available on a host.


As new containers are run, new images appear. All images are marked with a time stamp. If the image is running (the first list above) or is newly detected (the second list above), it is marked with the current time. The remaining images are already marked from the previous spins. All images are then sorted by the time stamp.

Once the collection starts, the oldest images get deleted first until the stopping criterion is met.
Configuring garbage collection for containers and images
As an administrator, you can configure how Red Hat OpenShift Container Platform performs garbage collection by creating a kubeletConfig object for each machine config pool.

Red Hat OpenShift Container Platform supports only one kubeletConfig object for each machine config pool.
You can configure any combination of the following:

Soft eviction for containers

Hard eviction for containers

Eviction for images


Container garbage collection removes terminated containers. Image garbage collection removes images that are not referenced by any running pods.

Obtain the label associated with the static MachineConfigPool CRD for the type of node you want to configure by entering the following command:


Create a custom resource (CR) for your configuration change.

Run the following command to create the CR:


Verify that garbage collection is active by entering the following command. The Machine Config Pool you specified in the custom resource appears with UPDATING as 'true` until the change is fully implemented: