# ClusterMonitoring [config.openshift.io/v1alpha1]


Description:: 
ClusterMonitoring is the Custom Resource object which holds the current status of Cluster Monitoring Operator. CMO is a central component of the monitoring stack.
Compatibility level 4: No compatibility is provided, the API can change at any point for any reason. These capabilities should not be used by applications needing long term support.
ClusterMonitoring is the Schema for the Cluster Monitoring Operators API
Type:: object
Required:: 
* spec

# Specification



## .spec

Description:: 
spec holds user configuration for the Cluster Monitoring Operator
Type:: object



## .spec.alertmanagerConfig

Description:: 
alertmanagerConfig allows users to configure how the default Alertmanager instance
should be deployed in the openshift-monitoring namespace.
alertmanagerConfig is optional.
When omitted, this means no opinion and the platform is left to choose a reasonable default, that is subject to change over time.
The current default value is DefaultConfig.
Type:: object
Required:: 
* deploymentMode



## .spec.alertmanagerConfig.customConfig

Description:: 
customConfig must be set when deploymentMode is CustomConfig, and must be unset otherwise.
When set to CustomConfig, the Alertmanager will be deployed with custom configuration.
Type:: object



## .spec.alertmanagerConfig.customConfig.resources

Description:: 
resources defines the compute resource requests and limits for the Alertmanager container.
This includes CPU, memory and HugePages constraints to help control scheduling and resource usage.
When not specified, defaults are used by the platform. Requests cannot exceed limits.
This field is optional.
More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
This is a simplified API that maps to Kubernetes ResourceRequirements.
The current default values are:
  resources:
   - name: cpu
     request: 4m
     limit: null
   - name: memory
     request: 40Mi
     limit: null
Maximum length for this list is 10.
Minimum length for this list is 1.
Type:: array

## .spec.alertmanagerConfig.customConfig.resources[]

Description:: 
ContainerResource defines a single resource requirement for a container.
Type:: object
Required:: 
* name



## .spec.alertmanagerConfig.customConfig.tolerations

Description:: 
tolerations defines tolerations for the pods.
tolerations is optional.
When omitted, this means the user has no opinion and the platform is left
to choose reasonable defaults. These defaults are subject to change over time.
Defaults are empty/unset.
Maximum length for this list is 10
Minimum length for this list is 1
Type:: array

## .spec.alertmanagerConfig.customConfig.tolerations[]

Description:: 
The pod this Toleration is attached to tolerates any taint that matches
the triple <key,value,effect> using the matching operator <operator>.
Type:: object



## .spec.alertmanagerConfig.customConfig.topologySpreadConstraints

Description:: 
topologySpreadConstraints defines rules for how Alertmanager Pods should be distributed
across topology domains such as zones, nodes, or other user-defined labels.
topologySpreadConstraints is optional.
This helps improve high availability and resource efficiency by avoiding placing
too many replicas in the same failure domain.
When omitted, this means no opinion and the platform is left to choose a default, which is subject to change over time.
This field maps directly to the topologySpreadConstraints field in the Pod spec.
Default is empty list.
Maximum length for this list is 10.
Minimum length for this list is 1
Entries must have unique topologyKey and whenUnsatisfiable pairs.
Type:: array

## .spec.alertmanagerConfig.customConfig.topologySpreadConstraints[]

Description:: 
TopologySpreadConstraint specifies how to spread matching pods among the given topology.
Type:: object
Required:: 
* maxSkew
* topologyKey
* whenUnsatisfiable



## .spec.alertmanagerConfig.customConfig.topologySpreadConstraints[].labelSelector

Description:: 
LabelSelector is used to find matching pods.
Pods that match this label selector are counted to determine the number of pods
in their corresponding topology domain.
Type:: object



## .spec.alertmanagerConfig.customConfig.topologySpreadConstraints[].labelSelector.matchExpressions

Description:: 
matchExpressions is a list of label selector requirements. The requirements are ANDed.
Type:: array

## .spec.alertmanagerConfig.customConfig.topologySpreadConstraints[].labelSelector.matchExpressions[]

Description:: 
A label selector requirement is a selector that contains values, a key, and an operator that
relates the key and values.
Type:: object
Required:: 
* key
* operator



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate

Description:: 
volumeClaimTemplate Defines persistent storage for Alertmanager. Use this setting to
configure the persistent volume claim, including storage class, volume
size, and name.
If omitted, the Pod uses ephemeral storage and alert data will not persist
across restarts.
This field is optional.
Type:: object



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.metadata

Description:: 
Standard object's metadata.
More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
Type:: object

## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.spec

Description:: 
spec defines the desired characteristics of a volume requested by a pod author.
More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
Type:: object



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.spec.dataSource

Description:: 
dataSource field can be used to specify either:
* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
* An existing PVC (PersistentVolumeClaim)
If the provisioner or an external controller can support the specified data source,
it will create a new volume based on the contents of the specified data source.
When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,
and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.
If the namespace is specified, then dataSourceRef will not be copied to dataSource.
Type:: object
Required:: 
* kind
* name



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.spec.dataSourceRef

Description:: 
dataSourceRef specifies the object from which to populate the volume with data, if a non-empty
volume is desired. This may be any object from a non-empty API group (non
core object) or a PersistentVolumeClaim object.
When this field is specified, volume binding will only succeed if the type of
the specified object matches some installed volume populator or dynamic
provisioner.
This field will replace the functionality of the dataSource field and as such
if both fields are non-empty, they must have the same value. For backwards
compatibility, when namespace isn't specified in dataSourceRef,
both fields (dataSource and dataSourceRef) will be set to the same
value automatically if one of them is empty and the other is non-empty.
When namespace is specified in dataSourceRef,
dataSource isn't set to the same value and must be empty.
There are three important differences between dataSource and dataSourceRef:
* While dataSource only allows two specific types of objects, dataSourceRef
  allows any non-core object, as well as PersistentVolumeClaim objects.
* While dataSource ignores disallowed values (dropping them), dataSourceRef
  preserves all values, and generates an error if a disallowed value is
  specified.
* While dataSource only allows local objects, dataSourceRef allows objects
  in any namespaces.
(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
Type:: object
Required:: 
* kind
* name



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.spec.resources

Description:: 
resources represents the minimum resources the volume should have.
If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements
that are lower than previous value but must still be higher than capacity recorded in the
status field of the claim.
More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
Type:: object



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.spec.selector

Description:: 
selector is a label query over volumes to consider for binding.
Type:: object



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.spec.selector.matchExpressions

Description:: 
matchExpressions is a list of label selector requirements. The requirements are ANDed.
Type:: array

## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.spec.selector.matchExpressions[]

Description:: 
A label selector requirement is a selector that contains values, a key, and an operator that
relates the key and values.
Type:: object
Required:: 
* key
* operator



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.status

Description:: 
status represents the current information/status of a persistent volume claim.
Read-only.
More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
Type:: object



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.status.conditions

Description:: 
conditions is the current Condition of persistent volume claim. If underlying persistent volume is being
resized then the Condition will be set to 'Resizing'.
Type:: array

## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.status.conditions[]

Description:: 
PersistentVolumeClaimCondition contains details about state of pvc
Type:: object
Required:: 
* status
* type



## .spec.alertmanagerConfig.customConfig.volumeClaimTemplate.status.modifyVolumeStatus

Description:: 
ModifyVolumeStatus represents the status object of ControllerModifyVolume operation.
When this is unset, there is no ModifyVolume operation being attempted.
Type:: object
Required:: 
* status



## .spec.metricsServerConfig

Description:: 
metricsServerConfig is an optional field that can be used to configure the Kubernetes Metrics Server that runs in the openshift-monitoring namespace.
Specifically, it can configure how the Metrics Server instance is deployed, pod scheduling, its audit policy and log verbosity.
When omitted, this means no opinion and the platform is left to choose a reasonable default, which is subject to change over time.
Type:: object



## .spec.metricsServerConfig.audit

Description:: 
audit defines the audit configuration used by the Metrics Server instance.
audit is optional.
When omitted, this means no opinion and the platform is left to choose a reasonable default, that is subject to change over time.
The current default sets audit.profile to Metadata
Type:: object
Required:: 
* profile



## .spec.metricsServerConfig.resources

Description:: 
resources defines the compute resource requests and limits for the Metrics Server container.
This includes CPU, memory and HugePages constraints to help control scheduling and resource usage.
When not specified, defaults are used by the platform. Requests cannot exceed limits.
This field is optional.
More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
This is a simplified API that maps to Kubernetes ResourceRequirements.
The current default values are:
  resources:
   - name: cpu
     request: 4m
     limit: null
   - name: memory
     request: 40Mi
     limit: null
Maximum length for this list is 10.
Minimum length for this list is 1.
Type:: array

## .spec.metricsServerConfig.resources[]

Description:: 
ContainerResource defines a single resource requirement for a container.
Type:: object
Required:: 
* name



## .spec.metricsServerConfig.tolerations

Description:: 
tolerations defines tolerations for the pods.
tolerations is optional.
When omitted, this means the user has no opinion and the platform is left
to choose reasonable defaults. These defaults are subject to change over time.
Defaults are empty/unset.
Maximum length for this list is 10
Minimum length for this list is 1
Type:: array

## .spec.metricsServerConfig.tolerations[]

Description:: 
The pod this Toleration is attached to tolerates any taint that matches
the triple <key,value,effect> using the matching operator <operator>.
Type:: object



## .spec.metricsServerConfig.topologySpreadConstraints

Description:: 
topologySpreadConstraints defines rules for how Metrics Server Pods should be distributed
across topology domains such as zones, nodes, or other user-defined labels.
topologySpreadConstraints is optional.
This helps improve high availability and resource efficiency by avoiding placing
too many replicas in the same failure domain.
When omitted, this means no opinion and the platform is left to choose a default, which is subject to change over time.
This field maps directly to the topologySpreadConstraints field in the Pod spec.
Default is empty list.
Maximum length for this list is 10.
Minimum length for this list is 1
Entries must have unique topologyKey and whenUnsatisfiable pairs.
Type:: array

## .spec.metricsServerConfig.topologySpreadConstraints[]

Description:: 
TopologySpreadConstraint specifies how to spread matching pods among the given topology.
Type:: object
Required:: 
* maxSkew
* topologyKey
* whenUnsatisfiable



## .spec.metricsServerConfig.topologySpreadConstraints[].labelSelector

Description:: 
LabelSelector is used to find matching pods.
Pods that match this label selector are counted to determine the number of pods
in their corresponding topology domain.
Type:: object



## .spec.metricsServerConfig.topologySpreadConstraints[].labelSelector.matchExpressions

Description:: 
matchExpressions is a list of label selector requirements. The requirements are ANDed.
Type:: array

## .spec.metricsServerConfig.topologySpreadConstraints[].labelSelector.matchExpressions[]

Description:: 
A label selector requirement is a selector that contains values, a key, and an operator that
relates the key and values.
Type:: object
Required:: 
* key
* operator



## .spec.userDefined

Description:: 
userDefined set the deployment mode for user-defined monitoring in addition to the default platform monitoring.
userDefined is optional.
When omitted, this means no opinion and the platform is left to choose a reasonable default, which is subject to change over time.
The current default value is Disabled.
Type:: object
Required:: 
* mode



## .status

Description:: 
status holds observed values from the cluster. They may not be overridden.
Type:: object

# API endpoints

The following API endpoints are available:

* /apis/config.openshift.io/v1alpha1/clustermonitorings
* DELETE: delete collection of ClusterMonitoring
* GET: list objects of kind ClusterMonitoring
* POST: create a ClusterMonitoring
* /apis/config.openshift.io/v1alpha1/clustermonitorings/{name}
* DELETE: delete a ClusterMonitoring
* GET: read the specified ClusterMonitoring
* PATCH: partially update the specified ClusterMonitoring
* PUT: replace the specified ClusterMonitoring
* /apis/config.openshift.io/v1alpha1/clustermonitorings/{name}/status
* GET: read status of the specified ClusterMonitoring
* PATCH: partially update status of the specified ClusterMonitoring
* PUT: replace status of the specified ClusterMonitoring

## /apis/config.openshift.io/v1alpha1/clustermonitorings

HTTP method:: DELETE
Description:: delete collection of ClusterMonitoring



HTTP method:: GET
Description:: list objects of kind ClusterMonitoring



HTTP method:: POST
Description:: create a ClusterMonitoring







## /apis/config.openshift.io/v1alpha1/clustermonitorings/{name}



HTTP method:: DELETE
Description:: delete a ClusterMonitoring





HTTP method:: GET
Description:: read the specified ClusterMonitoring



HTTP method:: PATCH
Description:: partially update the specified ClusterMonitoring





HTTP method:: PUT
Description:: replace the specified ClusterMonitoring







## /apis/config.openshift.io/v1alpha1/clustermonitorings/{name}/status



HTTP method:: GET
Description:: read status of the specified ClusterMonitoring



HTTP method:: PATCH
Description:: partially update status of the specified ClusterMonitoring





HTTP method:: PUT
Description:: replace status of the specified ClusterMonitoring





