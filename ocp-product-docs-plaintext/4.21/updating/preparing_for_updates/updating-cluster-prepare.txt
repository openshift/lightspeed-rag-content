# Preparing to update to Red Hat OpenShift Container Platform 4.20


Learn more about administrative tasks that cluster admins must perform to successfully initialize an update, as well as optional guidelines for ensuring a successful update.

# Kubernetes API removals

There are no Kubernetes API removals in this release.

# Assessing the risk of conditional updates

A conditional update is an update target that is available but not recommended due to a known risk that applies to your cluster.
The Cluster Version Operator (CVO) periodically queries the OpenShift Update Service (OSUS) for the most recent data about update recommendations, and some potential update targets might have risks associated with them.

The CVO evaluates the conditional risks, and if the risks are not applicable to the cluster, then the target version is available as a recommended update path for the cluster.
If the risk is determined to be applicable, or if for some reason CVO cannot evaluate the risk, then the update target is available to the cluster as a conditional update.

When you encounter a conditional update while you are trying to update to a target version, you must assess the risk of updating your cluster to that version.
Generally, if you do not have a specific need to update to that target version, it is best to wait for a recommended update path from Red Hat.

However, if you have a strong reason to update to that version, for example, if you need to fix an important CVE, then the benefit of fixing the CVE might outweigh the risk of the update being problematic for your cluster.
You can complete the following tasks to determine whether you agree with the Red Hat assessment of the update risk:

* Complete extensive testing in a non-production environment to the extent that you are comfortable completing the update in your production environment.
* Follow the links provided in the conditional update description, investigate the bug, and determine if it is likely to cause issues for your cluster. If you need help understanding the risk, contact Red Hat Support.

* Evaluation of update availability

# etcd backups before cluster updates

etcd backups record the state of your cluster and all of its resource objects.
You can use backups to attempt restoring the state of a cluster in disaster scenarios where you cannot recover a cluster in its currently dysfunctional state.

In the context of updates, you can attempt an etcd restoration of the cluster if an update introduced catastrophic conditions that cannot be fixed without reverting to the previous cluster version.
etcd restorations might be destructive and destabilizing to a running cluster, use them only as a last resort.


[WARNING]
----
Due to their high consequences, etcd restorations are not intended to be used as a rollback solution.
Rolling your cluster back to a previous version is not supported.
If your update is failing to complete, contact Red Hat support.
----

There are several factors that affect the viability of an etcd restoration.
For more information, see "Backing up etcd data" and "Restoring to a previous cluster state".

* Backing up etcd
* Restoring to a previous cluster state

# Preparing for Gateway API management succession by the Ingress Operator

Starting in Red Hat OpenShift Container Platform 4.19, the Ingress Operator manages the lifecycle of any Gateway API custom resource definitions (CRDs). This means that you will be denied access to creating, updating, and deleting any CRDs within the API groups that are grouped under Gateway API.

Updating from a version before 4.19 of Red Hat OpenShift Container Platform where this management was not present requires you to replace or remove any Gateway API CRDs that already exist in the cluster so that they conform to the specific Red Hat OpenShift Container Platform specification required by the Ingress Operator. Red Hat OpenShift Container Platform version 4.19 requires Gateway API Standard version 1.2.1 CRDs.


[WARNING]
----
Updating or deleting Gateway API resources can result in downtime and loss of service or data. Be sure you understand how this will affect your cluster before performing the steps in this procedure. If necessary, back up any Gateway API objects in YAML format in order to restore it later.
----

* You have installed the OpenShift CLI (oc).
* You have access to an Red Hat OpenShift Container Platform account with cluster administrator access.
* Optional: You have backed up any necessary Gateway API objects.

[WARNING]
----
Backup and restore can fail or result in data loss for any CRD fields that were present in the old definitions but are absent in the new definitions.
----

1. List all the Gateway API CRDs that you need to remove by running the following command:

```terminal
$ oc get crd | grep -F -e gateway.networking.k8s.io -e gateway.networking.x-k8s.io
```

Example output

```terminal
gatewayclasses.gateway.networking.k8s.io
gateways.gateway.networking.k8s.io
grpcroutes.gateway.networking.k8s.io
httproutes.gateway.networking.k8s.io
referencegrants.gateway.networking.k8s.io
```

2. Delete the Gateway API CRDs from the previous step by running the following command:

```terminal
$ oc delete crd gatewayclasses.networking.k8s.io && \
oc delete crd gateways.networking.k8s.io && \
oc delete crd grpcroutes.gateway.networking.k8s.io && \
oc delete crd httproutes.gateway.networking.k8s.io && \
oc delete crd referencesgrants.gateway.networking.k8s.io
```


[IMPORTANT]
----
Deleting CRDs removes every custom resource that relies on them and can result in data loss. Back up any necessary data before deleting the Gateway API CRDs. Any controller that was previously managing the lifecycle of the Gateway API CRDs will fail to operate properly. Attempting to force its use in conjunction with the Ingress Operator to manage Gateway API CRDs might prevent the cluster update from succeeding.
----
3. Get the supported Gateway API CRDs by running the following command:

```terminal
$ oc apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.2.1/standard-install.yaml
```


[WARNING]
----
You can perform this step without deleting your CRDs. If your update to a CRD removes a field that is used by a custom resource, you can lose data. Updating a CRD a second time, to a version that re-adds a field, can cause any previously deleted data to reappear. Any third-party controller that depends on a specific Gateway API CRD version that is not supported in Red Hat OpenShift Container Platform 4.21 will break upon updating that CRD to one supported by Red Hat.
For more information on the Red Hat OpenShift Container Platform implementation and the dead fields issue, see Gateway API implementation for Red Hat OpenShift Container Platform.
----

* Gateway API implementation for Red Hat OpenShift Container Platform

# Best practices for cluster updates

Red Hat OpenShift Container Platform provides a robust update experience that minimizes workload disruptions during an update.
Updates will not begin unless the cluster is in an upgradeable state at the time of the update request.

This design enforces some key conditions before initiating an update, but there are a number of actions you can take to increase your chances of a successful cluster update.

## Choose versions recommended by the OpenShift Update Service

The OpenShift Update Service (OSUS) provides update recommendations based on cluster characteristics such as the cluster&#8217;s subscribed channel.
The Cluster Version Operator saves these recommendations as either recommended or conditional updates.
While it is possible to attempt an update to a version that is not recommended by OSUS, following a recommended update path protects users from encountering known issues or unintended consequences on the cluster.

Choose only update targets that are recommended by OSUS to ensure a successful update.

## Address all critical alerts on the cluster

Critical alerts must always be addressed as soon as possible, but it is especially important to address these alerts and resolve any problems before initiating a cluster update.
Failing to address critical alerts before beginning an update can cause problematic conditions for the cluster.

In the Administrator perspective of the web console, navigate to Observe &#8594; Alerting to find critical alerts.

## Ensure that the cluster is in an Upgradable state

When one or more Operators have not reported their Upgradeable condition as True for more than an hour, the ClusterNotUpgradeable warning alert is triggered in the cluster.
In most cases this alert does not block patch updates, but you cannot perform a minor version update until you resolve this alert and all Operators report Upgradeable as True.

For more information about the Upgradeable condition, see "Understanding cluster Operator condition types" in the additional resources section.

### SDN support removal

OpenShift SDN network plugin was deprecated in versions 4.15 and 4.16. With this release, the SDN network plugin is no longer supported and the content has been removed from the documentation.

If your Red Hat OpenShift Container Platform cluster is still using the OpenShift SDN CNI, see Migrating from the OpenShift SDN network plugin.


[IMPORTANT]
----
It is not possible to update a cluster to Red Hat OpenShift Container Platform 4.17 if it is using the OpenShift SDN network plugin. You must migrate to the OVN-Kubernetes plugin before upgrading to Red Hat OpenShift Container Platform 4.17.
----

## Ensure that enough spare nodes are available

A cluster should not be running with little to no spare node capacity, especially when initiating a cluster update.
Nodes that are not running and available may limit a cluster&#8217;s ability to perform an update with minimal disruption to cluster workloads.

Depending on the configured value of the cluster&#8217;s maxUnavailable spec, the cluster might not be able to apply machine configuration changes to nodes if there is an unavailable node.
Additionally, if compute nodes do not have enough spare capacity, workloads might not be able to temporarily shift to another node while the first node is taken offline for an update.

Make sure that you have enough available nodes in each worker pool, as well as enough spare capacity on your compute nodes, to increase the chance of successful node updates.


[WARNING]
----
The default setting for maxUnavailable is 1 for all the machine config pools in Red Hat OpenShift Container Platform. It is recommended to not change this value and update one control plane node at a time. Do not change this value to 3 for the control plane pool.
----

## Ensure that the cluster's PodDisruptionBudget is properly configured

You can use the PodDisruptionBudget object to define the minimum number or percentage of pod replicas that must be available at any given time.
This configuration protects workloads from disruptions during maintenance tasks such as cluster updates.

However, it is possible to configure the PodDisruptionBudget for a given topology in a way that prevents nodes from being drained and updated during a cluster update.

When planning a cluster update, check the configuration of the PodDisruptionBudget object for the following factors:

* For highly available workloads, make sure there are replicas that can be temporarily taken offline without being prohibited by the PodDisruptionBudget.
* For workloads that are not highly available, make sure they are either not protected by a PodDisruptionBudget or have some alternative mechanism for draining these workloads eventually, such as periodic restart or guaranteed eventual termination.

* Understanding cluster Operator condition types