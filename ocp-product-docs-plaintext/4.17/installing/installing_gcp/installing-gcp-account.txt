# Configuring a GCP project


Before you can install Red Hat OpenShift Container Platform, you must configure a
Google Cloud Platform (GCP) project to host it.

# Creating a GCP project

To install Red Hat OpenShift Container Platform, you must create a project in your Google Cloud Platform (GCP) account to host the cluster.

* Create a project to host your Red Hat OpenShift Container Platform cluster. See
Creating and Managing Projects in the GCP documentation.

[IMPORTANT]
----
Your GCP project must use the Premium Network Service Tier if you are using installer-provisioned infrastructure. The Standard Network Service Tier is not supported for clusters installed using the installation program. The installation program configures internal load balancing for the api-int.<cluster_name>.<base_domain> URL; the Premium Tier is required for internal load balancing.
----

# Enabling API services in GCP

Your Google Cloud Platform (GCP) project requires access to several API services
to complete Red Hat OpenShift Container Platform installation.

* You created a project to host your cluster.

* Enable the following required API services in the project that hosts your
cluster. You may also enable optional API services which are not required for installation. See
Enabling services
in the GCP documentation.
Required API services

Optional API services


# Configuring DNS for GCP

To install Red Hat OpenShift Container Platform, the Google Cloud Platform (GCP) account you use must
have a dedicated public hosted zone
in the same project that you host the Red Hat OpenShift Container Platform cluster.
This zone must be authoritative for the domain. The
DNS service provides cluster DNS resolution and name lookup for external
connections to the cluster.

1. Identify your domain, or subdomain, and registrar. You can transfer an existing domain and
registrar or obtain a new one through GCP or another source.

[NOTE]
----
If you purchase a new domain, it can take time for the relevant DNS
changes to propagate. For more information about purchasing domains
through Google, see Google Domains.
----
2. Create a public hosted zone for your domain or subdomain in your GCP project. See
Creating public zones
in the GCP documentation.

Use an appropriate root domain, such as openshiftcorp.com, or subdomain,
such as clusters.openshiftcorp.com.
3. Extract the new authoritative name servers from the hosted zone records. See
Look up your Cloud DNS name servers
in the GCP documentation.

You typically have four name servers.
4. Update the registrar records for the name servers that your domain
uses. For example, if you registered your domain to Google Domains, see the
following topic in the Google Domains Help:
How to switch to custom name servers.
5. If you migrated your root domain to Google Cloud Platform DNS, migrate your DNS records. See Migrating to Cloud DNS in the GCP documentation.
6. If you use a subdomain, follow your company's procedures to add its delegation records to the parent domain. This process might include a request to your company's IT department or the division that controls the root domain and DNS services for your company.

# GCP account limits

The Red Hat OpenShift Container Platform cluster uses a number of Google Cloud Platform (GCP)
components, but the default
Quotas
do not affect your ability to install a default Red Hat OpenShift Container Platform cluster.

A default cluster, which contains three compute and three control plane machines,
uses the following resources. Note that some resources are required only during
the bootstrap process and are removed after the cluster deploys.




[NOTE]
----
If any of the quotas are insufficient during installation, the installation program displays an error that states both which quota was exceeded and the region.
----

Be sure to consider your actual cluster size, planned cluster growth, and any usage from other clusters that are associated with your account. The CPU, static IP addresses, and persistent disk SSD (storage) quotas are the ones that are most likely to be insufficient.

If you plan to deploy your cluster in one of the following regions, you will exceed the maximum storage quota and are likely to exceed the CPU quota limit:

* asia-east2
* asia-northeast2
* asia-south1
* australia-southeast1
* europe-north1
* europe-west2
* europe-west3
* europe-west6
* northamerica-northeast1
* southamerica-east1
* us-west2

You can increase resource quotas from the GCP console, but you might need to file a support ticket. Be sure to plan your cluster size early so that you can allow time to resolve the support ticket before you install your Red Hat OpenShift Container Platform cluster.

# Creating a service account in GCP

Red Hat OpenShift Container Platform requires a Google Cloud Platform (GCP) service account that provides authentication and authorization to access data in the Google APIs. If you do not have an existing IAM service account that contains the required roles in your project, you must create one.

* You created a project to host your cluster.

1. Create a service account in the project that you use to host your
Red Hat OpenShift Container Platform cluster. See
Creating a service account
in the GCP documentation.
2. Grant the service account the appropriate permissions. You can either
grant the individual permissions that follow or assign the Owner role to it.
See Granting roles to a service account for specific resources.

[NOTE]
----
While making the service account an owner of the project is the easiest way to gain the required permissions, it means that service account has complete control over the project. You must determine if the risk that comes from offering that power is acceptable.
----
3. You can create the service account key in JSON format, or attach the service account to a GCP virtual machine.
See Creating service account keys and Creating and enabling service accounts for instances in the GCP documentation.

[NOTE]
----
If you use a virtual machine with an attached service account to create your cluster, you must set credentialsMode: Manual in the install-config.yaml file before installation.
----

## Required GCP roles

When you attach the Owner role to the service account that you create, you grant that service account all permissions, including those that are required to install Red Hat OpenShift Container Platform. If your organization&#8217;s security policies require a more restrictive set of permissions, you can create a service account with the following permissions. If you deploy your cluster into an existing virtual private cloud (VPC), the service account does not require certain networking permissions, which are noted in the following lists:

* Compute Admin
* Role Administrator
* Security Admin
* Service Account Admin
* Service Account Key Admin
* Service Account User
* Storage Admin

* DNS Administrator

* Compute Load Balancer Admin
* Tag User

The following roles are applied to the service accounts that the control plane and compute machines use:



## Required GCP permissions for installer-provisioned infrastructure

When you attach the Owner role to the service account that you create, you grant that service account all permissions, including those that are required to install Red Hat OpenShift Container Platform.

If your organization’s security policies require a more restrictive set of permissions, you can create custom roles with the necessary permissions. The following permissions are required for the installer-provisioned infrastructure for creating and deleting the Red Hat OpenShift Container Platform cluster.

* compute.addresses.create
* compute.addresses.createInternal
* compute.addresses.delete
* compute.addresses.get
* compute.addresses.list
* compute.addresses.use
* compute.addresses.useInternal
* compute.firewalls.create
* compute.firewalls.delete
* compute.firewalls.get
* compute.firewalls.list
* compute.forwardingRules.create
* compute.forwardingRules.get
* compute.forwardingRules.list
* compute.forwardingRules.setLabels
* compute.globalAddresses.create
* compute.globalAddresses.get
* compute.globalAddresses.use
* compute.globalForwardingRules.create
* compute.globalForwardingRules.get
* compute.globalForwardingRules.setLabels
* compute.networks.create
* compute.networks.get
* compute.networks.list
* compute.networks.updatePolicy
* compute.networks.use
* compute.routers.create
* compute.routers.get
* compute.routers.list
* compute.routers.update
* compute.routes.list
* compute.subnetworks.create
* compute.subnetworks.get
* compute.subnetworks.list
* compute.subnetworks.use
* compute.subnetworks.useExternalIp

* compute.backendServices.create
* compute.backendServices.get
* compute.backendServices.list
* compute.backendServices.update
* compute.backendServices.use
* compute.regionBackendServices.create
* compute.regionBackendServices.get
* compute.regionBackendServices.list
* compute.regionBackendServices.update
* compute.regionBackendServices.use
* compute.targetPools.addInstance
* compute.targetPools.create
* compute.targetPools.get
* compute.targetPools.list
* compute.targetPools.removeInstance
* compute.targetPools.use
* compute.targetTcpProxies.create
* compute.targetTcpProxies.get
* compute.targetTcpProxies.use

* dns.changes.create
* dns.changes.get
* dns.managedZones.create
* dns.managedZones.get
* dns.managedZones.list
* dns.networks.bindPrivateDNSZone
* dns.resourceRecordSets.create
* dns.resourceRecordSets.list

* iam.serviceAccountKeys.create
* iam.serviceAccountKeys.delete
* iam.serviceAccountKeys.get
* iam.serviceAccountKeys.list
* iam.serviceAccounts.actAs
* iam.serviceAccounts.create
* iam.serviceAccounts.delete
* iam.serviceAccounts.get
* iam.serviceAccounts.list
* resourcemanager.projects.get
* resourcemanager.projects.getIamPolicy
* resourcemanager.projects.setIamPolicy

* compute.disks.create
* compute.disks.get
* compute.disks.list
* compute.disks.setLabels
* compute.instanceGroups.create
* compute.instanceGroups.delete
* compute.instanceGroups.get
* compute.instanceGroups.list
* compute.instanceGroups.update
* compute.instanceGroups.use
* compute.instances.create
* compute.instances.delete
* compute.instances.get
* compute.instances.list
* compute.instances.setLabels
* compute.instances.setMetadata
* compute.instances.setServiceAccount
* compute.instances.setTags
* compute.instances.use
* compute.machineTypes.get
* compute.machineTypes.list

* storage.buckets.create
* storage.buckets.delete
* storage.buckets.get
* storage.buckets.list
* storage.objects.create
* storage.objects.delete
* storage.objects.get
* storage.objects.list

* compute.healthChecks.create
* compute.healthChecks.get
* compute.healthChecks.list
* compute.healthChecks.useReadOnly
* compute.httpHealthChecks.create
* compute.httpHealthChecks.get
* compute.httpHealthChecks.list
* compute.httpHealthChecks.useReadOnly
* compute.regionHealthChecks.create
* compute.regionHealthChecks.get
* compute.regionHealthChecks.useReadOnly

* compute.globalOperations.get
* compute.regionOperations.get
* compute.regions.get
* compute.regions.list
* compute.zoneOperations.get
* compute.zones.get
* compute.zones.list

* monitoring.timeSeries.list
* serviceusage.quotas.get
* serviceusage.services.list

* iam.roles.create
* iam.roles.get
* iam.roles.update

* iam.serviceAccounts.signBlob

* compute.images.list

* compute.instances.getSerialPortOutput

* compute.addresses.delete
* compute.addresses.deleteInternal
* compute.addresses.list
* compute.addresses.setLabels
* compute.firewalls.delete
* compute.firewalls.list
* compute.forwardingRules.delete
* compute.forwardingRules.list
* compute.globalAddresses.delete
* compute.globalAddresses.list
* compute.globalForwardingRules.delete
* compute.globalForwardingRules.list
* compute.networks.delete
* compute.networks.list
* compute.networks.updatePolicy
* compute.routers.delete
* compute.routers.list
* compute.routes.list
* compute.subnetworks.delete
* compute.subnetworks.list

* compute.backendServices.delete
* compute.backendServices.list
* compute.regionBackendServices.delete
* compute.regionBackendServices.list
* compute.targetPools.delete
* compute.targetPools.list
* compute.targetTcpProxies.delete
* compute.targetTcpProxies.list

* dns.changes.create
* dns.managedZones.delete
* dns.managedZones.get
* dns.managedZones.list
* dns.resourceRecordSets.delete
* dns.resourceRecordSets.list

* iam.serviceAccounts.delete
* iam.serviceAccounts.get
* iam.serviceAccounts.list
* resourcemanager.projects.getIamPolicy
* resourcemanager.projects.setIamPolicy

* compute.disks.delete
* compute.disks.list
* compute.instanceGroups.delete
* compute.instanceGroups.list
* compute.instances.delete
* compute.instances.list
* compute.instances.stop
* compute.machineTypes.list

* storage.buckets.delete
* storage.buckets.getIamPolicy
* storage.buckets.list
* storage.objects.delete
* storage.objects.list

* compute.healthChecks.delete
* compute.healthChecks.list
* compute.httpHealthChecks.delete
* compute.httpHealthChecks.list
* compute.regionHealthChecks.delete
* compute.regionHealthChecks.list

* compute.images.list

## Required GCP permissions for shared VPC installations

When you are installing a cluster to a shared VPC, you must configure the service account for both the host project and the service project. If you are not installing to a shared VPC, you can skip this section.

You must apply the minimum roles required for a standard installation as listed above, to the service project.


[IMPORTANT]
----
You can use granular permissions for a Cloud Credential Operator that operates in either manual or mint credentials mode. You cannot use granular permissions in passthrough credentials mode.
----

Ensure that the host project applies one of the following configurations to the service account:

* projects/<host-project>/roles/dns.networks.bindPrivateDNSZone
* roles/compute.networkAdmin
* roles/compute.securityAdmin

* compute.firewalls.delete
* compute.networks.updatePolicy

* projects/<host-project>/roles/dns.networks.bindPrivateDNSZone
* roles/compute.networkUser

If you do not supply a service account for control plane nodes in the install-config.yaml file, please grant the below permissions to the service account in the host project. If you do not supply a service account for compute nodes in the install-config.yaml file, please grant the below permissions to the service account in the host project for cluster destruction.

* resourcemanager.projects.getIamPolicy
* resourcemanager.projects.setIamPolicy

## Required GCP permissions for user-provided service accounts

When you are installing a cluster, the compute and control plane nodes require their own service accounts.
By default, the installation program creates a service account for the control plane and compute nodes.
The service account that the installation program uses requires the roles and permissions that are listed in the Creating a service account in GCP section, as well as the resourcemanager.projects.getIamPolicy and resourcemanager.projects.setIamPolicy permissions.
These permissions should be applied to the service account in the host project.
If this approach does not meet the security requirements of your organization, you can provide a service account email address for the control plane or compute nodes in the install-config.yaml file.
For more information, see the Installation configuration parameters for GCP page.
If you provide a service account for control plane nodes during an installation into a shared VPC, you must grant that service account the roles/compute.networkUser role in the host project.
If you want the installation program to automatically create firewall rules when you supply the control plane service account, you must grant that service account the roles/compute.networkAdmin and roles/compute.securityAdmin roles in the host project.
If you only supply the roles/compute.networkUser role, you must create the firewall rules manually.


[IMPORTANT]
----
The following roles are required for user-provided service accounts for control plane and compute nodes respectively.
----

* roles/compute.instanceAdmin
* roles/compute.networkAdmin
* roles/compute.securityAdmin
* roles/storage.admin

* roles/compute.viewer
* roles/storage.admin
* roles/artifactregistry.reader

# Supported GCP regions

You can deploy an Red Hat OpenShift Container Platform cluster to the following Google Cloud Platform (GCP)
regions:

* africa-south1 (Johannesburg, South Africa)
* asia-east1 (Changhua County, Taiwan)
* asia-east2 (Hong Kong)
* asia-northeast1 (Tokyo, Japan)
* asia-northeast2 (Osaka, Japan)
* asia-northeast3 (Seoul, South Korea)
* asia-south1 (Mumbai, India)
* asia-south2 (Delhi, India)
* asia-southeast1 (Jurong West, Singapore)
* asia-southeast2 (Jakarta, Indonesia)
* australia-southeast1 (Sydney, Australia)
* australia-southeast2 (Melbourne, Australia)
* europe-central2 (Warsaw, Poland)
* europe-north1 (Hamina, Finland)
* europe-southwest1 (Madrid, Spain)
* europe-west1 (St. Ghislain, Belgium)
* europe-west2 (London, England, UK)
* europe-west3 (Frankfurt, Germany)
* europe-west4 (Eemshaven, Netherlands)
* europe-west6 (Zürich, Switzerland)
* europe-west8 (Milan, Italy)
* europe-west9 (Paris, France)
* europe-west12 (Turin, Italy)
* me-central1 (Doha, Qatar, Middle East)
* me-central2 (Dammam, Saudi Arabia, Middle East)
* me-west1 (Tel Aviv, Israel)
* northamerica-northeast1 (Montréal, Québec, Canada)
* northamerica-northeast2 (Toronto, Ontario, Canada)
* southamerica-east1 (São Paulo, Brazil)
* southamerica-west1 (Santiago, Chile)
* us-central1 (Council Bluffs, Iowa, USA)
* us-east1 (Moncks Corner, South Carolina, USA)
* us-east4 (Ashburn, Northern Virginia, USA)
* us-east5 (Columbus, Ohio)
* us-south1 (Dallas, Texas)
* us-west1 (The Dalles, Oregon, USA)
* us-west2 (Los Angeles, California, USA)
* us-west3 (Salt Lake City, Utah, USA)
* us-west4 (Las Vegas, Nevada, USA)


[NOTE]
----
To determine which machine type instances are available by region and zone, see the Google documentation.
----

# Next steps

* Install an Red Hat OpenShift Container Platform cluster on GCP. You can
install a customized cluster
or quickly install a cluster
with default options.