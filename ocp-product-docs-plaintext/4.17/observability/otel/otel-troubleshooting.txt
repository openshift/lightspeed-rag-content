# Troubleshooting


The OpenTelemetry Collector offers multiple ways to measure its health as well as investigate data ingestion issues.

# Getting the OpenTelemetry Collector logs

You can get the logs for the OpenTelemetry Collector as follows.

1. Set the relevant log level in the OpenTelemetryCollector custom resource (CR):

```yaml
  config: |
    service:
      telemetry:
        logs:
          level: debug 1
```

Collector's log level. Supported values include info, warn, error, or debug. Defaults to info.
2. Use the oc logs command or the web console to retrieve the logs.

# Exposing the metrics

The OpenTelemetry Collector exposes the metrics about the data volumes it has processed. The following metrics are for spans, although similar metrics are exposed for metrics and logs signals:

otelcol_receiver_accepted_spans:: The number of spans successfully pushed into the pipeline.
otelcol_receiver_refused_spans:: The number of spans that could not be pushed into the pipeline.
otelcol_exporter_sent_spans:: The number of spans successfully sent to the destination.
otelcol_exporter_enqueue_failed_spans:: The number of spans failed to be added to the sending queue.

The Operator creates a <cr_name>-collector-monitoring telemetry service that you can use to scrape the metrics endpoint.

1. Enable the telemetry service by adding the following lines in the OpenTelemetryCollector custom resource (CR):

```yaml
# ...
  config: |
    service:
      telemetry:
        metrics:
          address: ":8888" 1
# ...
```

The address at which the internal collector metrics are exposed. Defaults to :8888.
2. Retrieve the metrics by running the following command, which uses the port-forwarding Collector pod:

```terminal
$ oc port-forward <collector_pod>
```

3. In the OpenTelemetryCollector CR, set the enableMetrics field to true to scrape internal metrics:

```yaml
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
spec:
# ...
  mode: deployment
  observability:
    metrics:
      enableMetrics: true
# ...
```


Depending on the deployment mode of the OpenTelemetry Collector, the internal metrics are scraped by using PodMonitors or ServiceMonitors.

[NOTE]
----
Alternatively, if you do not set the enableMetrics field to true, you can access the metrics endpoint at http://localhost:8888/metrics.
----
4. On the Observe page in the web console, enable User Workload Monitoring to visualize the scraped metrics.

[NOTE]
----
Not all processors expose the required metrics.
----
5. In the web console, go to Observe -> Dashboards and select the OpenTelemetry Collector dashboard from the drop-down list to view it.

[TIP]
----
You can filter the visualized data such as spans or metrics by the Collector instance, namespace, or OpenTelemetry components such as processors, receivers, or exporters.
----

# Debug exporter

You can configure the debug exporter to export the collected data to the standard output.

1. Configure the OpenTelemetryCollector custom resource as follows:

```yaml
  config: |
    exporters:
      debug:
        verbosity: detailed
    service:
      pipelines:
        traces:
          exporters: [debug]
        metrics:
          exporters: [debug]
        logs:
          exporters: [debug]
```

2. Use the oc logs command or the web console to export the logs to the standard output.