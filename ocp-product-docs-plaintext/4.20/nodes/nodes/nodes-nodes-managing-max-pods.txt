# Managing the maximum number of pods per node


In {product-title}, you can configure the number of pods that can run on a node based on the number of
processor cores on the node, a hard limit or both. If you use both options,
the lower of the two limits the number of pods on a node.
When both options are in use, the lower of the two values limits the number of
pods on a node. Exceeding these values can result in:
* Increased CPU utilization.
* Slow pod scheduling.
* Potential out-of-memory scenarios, depending on the amount of memory in the node.
* Exhausting the pool of IP addresses.
* Resource overcommitting, leading to poor user application performance.

[IMPORTANT]
----
In Kubernetes, a pod that is holding a single container actually uses two
containers. The second container is used to set up networking prior to the
actual container starting. Therefore, a system running 10 pods will actually
have 20 containers running.
----

[NOTE]
----
Disk IOPS throttling from the cloud provider might have an impact on CRI-O and kubelet.
They might get overloaded when there are large number of I/O intensive pods running on
the nodes. It is recommended that you monitor the disk I/O on the nodes and use volumes
with sufficient throughput for the workload.
----
The podsPerCore parameter sets the number of pods the node can run based on the number of
processor cores on the node. For example, if podsPerCore is set to 10 on a
node with 4 processor cores, the maximum number of pods allowed on the node will
be 40.

```yaml
kubeletConfig:
  podsPerCore: 10
```

Setting podsPerCore to 0 disables this limit. The default is 0.
The value of the podsPerCore parameter cannot exceed the value of the maxPods parameter.
The maxPods parameter sets the number of pods the node can run to a fixed value, regardless
of the properties of the node.

```yaml
 kubeletConfig:
    maxPods: 250
```

# Configuring the maximum number of pods per node

Two parameters control the maximum number of pods that can be scheduled to a node: podsPerCore and maxPods. If you use both options, the lower of the two limits the number of pods on a node.

For example, if podsPerCore is set to 10 on a node with 4 processor cores, the maximum number of pods allowed on the node will be 40.

1. Obtain the label associated with the static MachineConfigPool CRD for the type of node you want to configure by entering the following command:

```terminal
$ oc edit machineconfigpool <name>
```


For example:

```terminal
$ oc edit machineconfigpool worker
```

Example output

```yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfigPool
metadata:
  creationTimestamp: "2022-11-16T15:34:25Z"
  generation: 4
  labels:
    pools.operator.machineconfiguration.openshift.io/worker: "" 1
  name: worker
#...
```

The label appears under Labels.

[TIP]
----
If the label is not present, add a key/value pair such as:

```
$ oc label machineconfigpool worker custom-kubelet=small-pods
```

----

1. Create a custom resource (CR) for your configuration change.
Sample configuration for a max-pods CR

```yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: KubeletConfig
metadata:
  name: set-max-pods 1
spec:
  machineConfigPoolSelector:
    matchLabels:
      pools.operator.machineconfiguration.openshift.io/worker: "" 2
  kubeletConfig:
    podsPerCore: 10 3
    maxPods: 250 4
#...
```

Assign a name to CR.
Specify the label from the machine config pool.
Specify the number of pods the node can run based on the number of processor cores on the node.
Specify the number of pods the node can run to a fixed value, regardless of the properties of the node.

[NOTE]
----
Setting podsPerCore to 0 disables this limit.
----

In the above example, the default value for podsPerCore is 10 and the default value for maxPods is 250. This means that unless the node has 25 cores or more, by default, podsPerCore will be the limiting factor.
2. Run the following command to create the CR:

```terminal
$ oc create -f <file_name>.yaml
```


1. List the MachineConfigPool CRDs to see if the change is applied. The UPDATING column reports True if the change is picked up by the Machine Config Controller:

```terminal
$ oc get machineconfigpools
```

Example output

```terminal
NAME     CONFIG                        UPDATED   UPDATING   DEGRADED
master   master-9cc2c72f205e103bb534   False     False      False
worker   worker-8cecd1236b33ee3f8a5e   False     True       False
```


Once the change is complete, the UPDATED column reports True.

```terminal
$ oc get machineconfigpools
```

Example output

```terminal
NAME     CONFIG                        UPDATED   UPDATING   DEGRADED
master   master-9cc2c72f205e103bb534   False     True       False
worker   worker-8cecd1236b33ee3f8a5e   True      False      False
```
