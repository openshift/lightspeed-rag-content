# Placing pods onto overcommited nodes


In an overcommited state, the sum of the container compute resource requests and limits exceeds the resources available on the system.
Overcommitment might be desirable in development environments where a trade-off of guaranteed performance for capacity is acceptable.
Requests and limits enable administrators to allow and manage the overcommitment of resources on a node.
The scheduler uses requests for scheduling your container and providing a minimum service guarantee.
Limits constrain the amount of compute resource that may be consumed on your node.

# Understanding overcommitment

Requests and limits enable administrators to allow and manage the overcommitment of resources on a node. The scheduler uses requests for scheduling your container and providing a minimum service guarantee. Limits constrain the amount of compute resource that may be consumed on your node.

Red Hat OpenShift Container Platform administrators can control the level of overcommit and manage container density on nodes by configuring masters to override the ratio between request and limit set on developer containers. In conjunction with a per-project LimitRange object specifying limits and defaults, this adjusts the container limit and request to achieve the desired level of overcommit.


[NOTE]
----
That these overrides have no effect if no limits have been set on containers. Create a LimitRange object with default limits, per individual project, or in the project template, to ensure that the overrides apply.
----

After these overrides, the container limits and requests must still be validated by any LimitRange object in the project. It is possible, for example, for developers to specify a limit close to the minimum limit, and have the request then be overridden below the minimum limit, causing the pod to be forbidden. This unfortunate user experience should be addressed with future work, but for now, configure this capability and LimitRange objects with caution.

# Understanding nodes overcommitment

In an overcommitted environment, it is important to properly configure your node to provide best system behavior.

When the node starts, it ensures that the kernel tunable flags for memory
management are set properly. The kernel should never fail memory allocations
unless it runs out of physical memory.

To ensure this behavior, Red Hat OpenShift Container Platform configures the kernel to always overcommit
memory by setting the vm.overcommit_memory parameter to 1, overriding the
default operating system setting.

Red Hat OpenShift Container Platform also configures the kernel not to panic when it runs out of memory
by setting the vm.panic_on_oom parameter to 0. A setting of 0 instructs the
kernel to call oom_killer in an Out of Memory (OOM) condition, which kills
processes based on priority

You can view the current setting by running the following commands on your nodes:


```terminal
$ sysctl -a |grep commit
```



```terminal
#...
vm.overcommit_memory = 0
#...
```



```terminal
$ sysctl -a |grep panic
```



```terminal
#...
vm.panic_on_oom = 0
#...
```



[NOTE]
----
The above flags should already be set on nodes, and no further action is
required.
----

You can also perform the following configurations for each node:

* Disable or enforce CPU limits using CPU CFS quotas
* Reserve resources for system processes
* Reserve memory across quality of service tiers